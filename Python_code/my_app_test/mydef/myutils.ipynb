{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ce2099-0a89-4d69-9cd8-9c247c764701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(\n",
    "    img,\n",
    "    new_shape=(640, 640),\n",
    "    color=(0, 0, 0),\n",
    "    scaleup=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    指定されたサイズに画像をリサイズを行う。\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    img : (ndarray) 画像のndarray配列\n",
    "    new_shape : (tuple) リサイズしたい画像サイズ\n",
    "    color : (tuple:(B, G, R)) パディングの色\n",
    "    scaleup : (Bool) スケールアップを行う場合はTrue\n",
    "\n",
    "    Return\n",
    "    -----------\n",
    "    padded_img : (ndarray) リサイズされた画像のndarray配列\n",
    "    ratio : (tuple リサイズした比率\n",
    "    (dw, dh) : (int:(横、高さ)) パディングした数値(横、高さ)\n",
    "    \"\"\"\n",
    "    \n",
    "    # アスペクト比を保った画像のリサイズ\n",
    "    ori_shape = img.shape[:2] # [H, W, C] -> [H, W]\n",
    "    r = min(new_shape[0] / ori_shape[0], new_shape[1] / ori_shape[1])\n",
    "    \n",
    "    # スケールアップなしの場合\n",
    "    if not scaleup:\n",
    "        r = min(r, 1.0)\n",
    "    \n",
    "    # アスペクト比を保ったまま、リスケール\n",
    "    ratio = (r, r)\n",
    "    new_unpad = (round(ori_shape[1] * r), round(ori_shape[0] * r)) # cv.resizeのため[W, H]にする\n",
    "    \n",
    "    # パディングする領域を算出\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]\n",
    "    dw, dh = dw / 2, dh / 2\n",
    "\n",
    "    # dw, dfが.5の時の対応 -> この微調整をしないとsession.run()時のinputのshapeが合わなくなる\n",
    "    top, bottom = round(dh - 0.1), round(dh + 0.1)\n",
    "    left, right = round(dw - 0.1), round(dw + 0.1)\n",
    "    \n",
    "    # 画像のリサイズ\n",
    "    if new_shape[::-1] != new_unpad:\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    padded_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20bfb45f-d793-4b87-ba40-67741f422679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh2xyxy(x):\n",
    "    \"\"\"\n",
    "    [x中心、y中心、bboxの幅, bboxの高さ] -> [bboxの左上のx、bboxの左上のy, bboxの右下のx, bboxの右下のy]\n",
    "    \"\"\"\n",
    "    y = x.clone()\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2  # bboxの左上のx\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2  # bboxの左上のy\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2  # bboxの右下のx\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2  # bboxの右下のy\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84aed0cb-3bf3-4d00-83e8-d58041316b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(\n",
    "    prediction, \n",
    "    conf_thres=0.25,\n",
    "    iou_thres=0.45,\n",
    "    agnostic=False,\n",
    "    labels=(),\n",
    "    max_det=300,\n",
    "    nm=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    \n",
    "    YOLOの予測結果をNMS処理する。\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    prediction : (tensor) テンソル化したyoloが予測した結果\n",
    "    conf_thres : (float) バウンディングボックス(bbox)の信頼度スコアの閾値\n",
    "    iou_thres : (float) IOUの閾値\n",
    "    agnostic : (Bool) 重なった異なるクラスのbboxを同一のbboxにするか\n",
    "    labels : (tuple or list-like) 画像内のラベルの情報\n",
    "    max_det : (int) 最大のbbox数\n",
    "    nm : (int) マスク数\n",
    "    \n",
    "    Return\n",
    "    -----------\n",
    "    output : (tensor) NMS処理後のbbox情報を含むテンソル、[x1, y1, x2, y2, クラス確率, cls_id]のカラムに変換されている\n",
    "                      x1,y1はbboxの左上のx,y座標、x2, y2は右下のx,y座標を表す\n",
    "                      \n",
    "    \"\"\"\n",
    "    batch_size = prediction.shape[0] # バッチサイズ\n",
    "    num_class = prediction.shape[2] - nm - 5 # クラス数\n",
    "    bool_cnf = prediction[..., 4] > conf_thres # bbox毎に信頼度スコアがconf_thresより大きいかのbool\n",
    "    \n",
    "    max_wh = 7680  # 最大のbboxの幅、高さ\n",
    "    max_nms = 30000  # torchvision.ops.nms()のための最大のbbox数\n",
    "    time_limit = 0.5 + 0.05 * batch_size  # タイムリミット(s)\n",
    "    \n",
    "    start = time.time()\n",
    "    mi = 5 + num_class\n",
    "    output = [torch.zeros((0, 6 + nm), device=prediction.device)] * batch_size\n",
    "    \n",
    "    \n",
    "    for idx, x in enumerate(prediction):\n",
    "    \n",
    "        # conf_thresより大きい信頼度スコアを持つbboxsを抽出\n",
    "        x = x[bool_cnf[idx]]\n",
    "    \n",
    "        # labelsを持っていた時の処理\n",
    "        if labels and len(labels[idx]):\n",
    "                lb = labels[idx]\n",
    "                v = torch.zeros((len(lb), num_class + nm + 5), device=x.device)\n",
    "                v[:, :4] = lb[:, 1:5]  # box\n",
    "                v[:, 4] = 1.0  # conf\n",
    "                v[range(len(lb)), lb[:, 0].long() + 5] = 1.0  # cls\n",
    "                x = torch.cat((x, v), 0)\n",
    "            \n",
    "    \n",
    "        # フィルター後のbboxがない場合\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        x[:, 5:] *= x[:, 4:5] # 信頼度スコア*各cls確率\n",
    "        box = xywh2xyxy(x[:, :4]) # [x1, y1, x2, y2]:bboxの左上と右下の座標に変換\n",
    "        mask = x[:, mi:] # maskがなければ[]\n",
    "    \n",
    "        cls_prob, cls_id = x[:, 5:mi].max(1, keepdim=True) # 各bboxで確率の高いclsの値とcls_idを返す\n",
    "    \n",
    "        # [x1, y1, x2, y2, clsの確率, cls_id]のカラムの順に結合\n",
    "        # clsの確率(本来のprob*信頼度スコア)がconf_thresより高いもののみ抽出\n",
    "        x = torch.cat((box, cls_prob, cls_id.float(), mask), axis=1)[cls_prob.view(-1) > conf_thres]\n",
    "    \n",
    "        \n",
    "        n = x.shape[0]\n",
    "        if not n:\n",
    "            continue\n",
    "    \n",
    "        # cls確率をキーにして降順に並び替え、且つ max_nmsを超えないようにする\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]] \n",
    "    \n",
    "        # 異なるクラスのbboxを区別して評価するため、agnosticでクラス固有のbboxを作成\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
    "    \n",
    "        # nms\n",
    "        selected_idx = torchvision.ops.nms(boxes, scores, iou_thres)\n",
    "        selected_idx = selected_idx[:max_det]\n",
    "\n",
    "        output[idx] = x[selected_idx]\n",
    "        finish = time.time()\n",
    "        if (finish - start) > time_limit:\n",
    "            break\n",
    "            \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09df6764-a2c5-40a8-9116-75f35fa82bcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#==============\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 画像の前処理\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#==============\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m np_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(input_file)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 画像のリサイズ\u001b[39;00m\n\u001b[1;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m letterbox(np_img, [\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#==============\n",
    "# 画像の前処理\n",
    "#==============\n",
    "\n",
    "np_img = cv2.imread(input_file)\n",
    "\n",
    "# 画像のリサイズ\n",
    "img = letterbox(np_img, [640, 640])[0]\n",
    "\n",
    "# (H,W,C) -> (C, H, W)\n",
    "# BGR -> RGB\n",
    "img = img.transpose((2, 0, 1))[::-1]\n",
    "img = np.ascontiguousarray(img)\n",
    "\n",
    "# テンソル化 -> 正規化\n",
    "img = torch.from_numpy(img)\n",
    "img = img.half() if fp16 else img.float()\n",
    "scaled_img = img / 255\n",
    "scaled_img = scaled_img.unsqueeze(0)\n",
    "\n",
    "\n",
    "# ===============\n",
    "# 推論 \n",
    "# ===============\n",
    "\n",
    "scaled_img = scaled_img.cpu().numpy()\n",
    "output_name = session.get_outputs()[0].name\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "# yのshape:[データ数、bbox数, メタ情報]\n",
    "# メタ情報:[x中心, y中心, bboxの幅, bboxの高さ, 信頼スコア、 押印の確率, 未押印の確率]\n",
    "y = session.run([output_name], {input_name: scaled_img})[0]\n",
    "pred = torch.from_numpy(y) # テンソル化\n",
    "\n",
    "# NMS処理\n",
    "pred = non_max_suppression(pred, conf_thres, iou_thres, agnostic_nms, max_det=max_det)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271247d-ed94-4f74-905d-b69974b540d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============\n",
    "# 出力処理 \n",
    "# ==============\n",
    "pred_cls_list = pred[0][:, -1] # 全bboxのクラス識別結果\n",
    "no_seal_cls_id = list(eval(meta['names']))[1] # 未押印のcls_id\n",
    "\n",
    "\n",
    "# 未押印の識別があったら、画像出力の分岐\n",
    "if no_seal_cls_id in pred_cls_list:\n",
    "\n",
    "    # --- 未押印あり -> bboxつきの画像配列を渡す処理 -------------\n",
    "    for det in pred:\n",
    "        process_img = np_img.copy() # np化したオリジナルimg\n",
    "        if len(det):\n",
    "    \n",
    "            # bboxの情報をオリジナル画像用に調整\n",
    "            det[:, :4] = scale_boxes(scaled_img.shape[2:], det[:, :4], process_img.shape).round()\n",
    "    \n",
    "            # bbox毎にイテレート\n",
    "            for *xyxy, prob, cls_id in reversed(det):\n",
    "                cls_id = int(cls_id)\n",
    "    \n",
    "                # bboxの色 (cv2に合わせるため、BGR)、YOLOv5に合わせている\n",
    "                # class_id:[0, 1]の2クラス用 -> いずれclassにしたら、インスタンス変数にしたい\n",
    "                color = [(56, 56, 255), (151, 157, 255)][cls_id]\n",
    "                label = names if hide_conf else f\"{names[cls_id]} {prob:.2f}\"\n",
    "    \n",
    "                # 最後にPILで処理されて,ChannelがRGBに変わっているので注意!!\n",
    "                process_img = box_label(img = process_img, box = xyxy, label = label, color = color)\n",
    "    \n",
    "            # POSTのResponseのため、RGBに変換後、(C, H, W)に転置する。\n",
    "            output_img = cv2.cvtColor(process_img, cv2.COLOR_BGR2RGB)\n",
    "            output_img = np.transpose(output_img, (2, 0, 1))\n",
    "\n",
    "    # 未押印cls_idとbbox付き画像のndarray配列を返す\n",
    "    print('return 1, output_img')\n",
    "\n",
    "else:\n",
    "    \n",
    "    # --- 未押印なし -> ファイル名とコメントを返す -------------\n",
    "    # filename = os.path.basename(input_file)\n",
    "    # comment = '未押印なし'\n",
    "\n",
    "    # # Responseするoutput [filename, comment, 押印のcls_id]\n",
    "    # output = [filename, comment, 0]\n",
    "    # print('return output')\n",
    "    # print('return only seal')\n",
    "\n",
    "    # --- 未押印なし -> cls_idとNoneを返す -------------\n",
    "\n",
    "    print(\"return 0, None\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

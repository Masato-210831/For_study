{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaabc7a3-91fe-4f36-9f64-b8e308d4bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2d9ba-6d12-40a3-9a83-96a625de51e2",
   "metadata": {},
   "source": [
    "画像分類のチューニング手法  \n",
    "・ニューラルネットワークの多層化  \n",
    "・最適化関数の改善  \n",
    "・過学習対策 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f45a3-726f-425d-a8bb-382d419adeec",
   "metadata": {},
   "source": [
    "## ドロップアウト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a0a30fc-1fc3-42c8-9941-ba606e9e5770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969,  0.2093, -0.9724, -0.7550,\n",
       "          0.3239, -0.1085]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ダミーデータの準備\n",
    "torch.manual_seed(123)\n",
    "inputs = torch.randn((1, 10))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58a57e6f-ee72-4445-a7f3-e3c38f3adce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[-0.0000,  0.2407, -0.0000, -0.4808, -0.0000,  0.0000, -1.9447, -0.0000,\n",
      "          0.6478, -0.2170]])\n",
      "ドロップされていない数: 5\n",
      "\n",
      "=====================\n",
      "\n",
      "False\n",
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969,  0.2093, -0.9724, -0.7550,\n",
      "          0.3239, -0.1085]])\n",
      "ドロップされていない数: 0\n"
     ]
    }
   ],
   "source": [
    "# ドロップアウト\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "# 訓練フェーズ\n",
    "dropout.train()\n",
    "print(dropout.training)\n",
    "\n",
    "outputs = dropout(inputs)\n",
    "print(outputs)\n",
    "no_drop=torch.sum(outputs==0).item()\n",
    "print(f'ドロップされていない数: {no_drop}')\n",
    "\n",
    "print(\"\\n=====================\\n\")\n",
    "\n",
    "# 予想フェーズ\n",
    "dropout.eval()\n",
    "print(dropout.training)\n",
    "output = dropout(inputs)\n",
    "print(output)\n",
    "no_drop=torch.sum(output==0).item()\n",
    "print(f'ドロップされていない数: {no_drop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fdba8a-78c9-4eaf-8c66-2d9cf3bf37fa",
   "metadata": {},
   "source": [
    "＜Point＞  \n",
    "・drop比率を0.5に指定したから正確に10中5個ドロップされるわけではない。 -> どの程度の確率でドロップするかの意味  \n",
    "・0でない値は1/(1-p)を掛けて、入力値全体のの平均がドロップアウト後も変わらないようにしている。\n",
    "・過学習には強いが、学習にかかる時間が長くなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb110a-7b1a-498a-a4bd-7ad3d44ba9c8",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc59a56-1b46-4009-966a-e553b5a81ee1",
   "metadata": {},
   "source": [
    "＜Point＞  \n",
    "・畳み込みではnn.BatchNorm2d, 線形ではnn.Batch1dを利用  \n",
    "・インスタンス生成時に必要な引数　2d -> 入力データのチャネル数, 1d -> 入力データの次元数  \n",
    "・学習対象パラメータにweightとbiasがある。  \n",
    "・訓練フェーズと予想フェーズで挙動が異なる。  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33735a4-9dba-4c68-92e2-214ea74a13fb",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520fae7-f393-43c7-9534-fe5e585e608a",
   "metadata": {},
   "source": [
    "＜Point＞  \n",
    "・Transformsで実装する\n",
    "・使用するData Augmentationによって入力データの形式が異なるので注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86a30742-e7f1-41f0-b910-164a052d66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cov = nn.Conv2d(1, 1, 1, padding=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a715ec6-4b2a-42fb-9b67-6949f5cc48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn((1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f47c8f9-94c7-4546-8060-79100e8c5ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3550, 0.3550, 0.3550],\n",
       "         [0.3550, 0.3550, 0.3550],\n",
       "         [0.3550, 0.9713, 0.3550],\n",
       "         [0.3550, 0.3550, 0.3550],\n",
       "         [0.3550, 0.3550, 0.3550]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cov(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3606cab9-da4b-4152-af7e-a8734a6eaa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0080]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56a25f51-bca2-4368-a16f-a57649f607d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0.6115]]]], requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cov.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c478c9b-95ce-472d-86ac-28f1a6084004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3550], requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cov.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602ff8f-b302-4e36-9366-9b6bc49ef132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917124ba-c5b6-472c-8cd1-f1cd7e6f4d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c28e21-4f70-40f3-8623-69bd3a991376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328ac18-9d51-41eb-9049-a85320100861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb283e7-10f6-4077-aa2b-bfd81982fcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b629b-f4cf-4afa-a289-89d961dc74e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f0247-bf1b-42e5-9c41-0a2f145853b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856dcdf-9537-4585-8558-3034ca5d8fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134193b-3dc2-4315-86da-5c4ffe7b2ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

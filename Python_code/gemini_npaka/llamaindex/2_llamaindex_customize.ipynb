{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf_XcjXD89hw"
   },
   "source": [
    "### LlamaIndexの前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mkPbwp6-ploX",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index==0.10.39 in /usr/local/lib/python3.11/site-packages (0.10.39)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.13)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.39 (from llama-index==0.10.39)\n",
      "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.11)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.6)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.31)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.9)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.7)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.33)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.11/site-packages (from llama-index==0.10.39) (0.1.6)\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.39) (1.54.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.4.2)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.16.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.19 in /usr/local/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.39) (0.1.19)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.39) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.39) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.39) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.39) (0.4.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.39) (2.6)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.0.6)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2024.11.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.39) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.39) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.39->llama-index==0.10.39) (0.2.0)\n",
      "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.22\n",
      "    Uninstalling llama-index-core-0.11.22:\n",
      "      Successfully uninstalled llama-index-core-0.11.22\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-huggingface 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-postprocessor-flag-embedding-reranker 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-llms-gemini 0.3.7 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.10.68.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.11/site-packages (from llama-index-llms-gemini) (0.5.4)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-llms-gemini)\n",
      "  Using cached llama_index_core-0.11.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-llms-gemini) (10.4.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.22.0)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.36.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.25.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.9.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.25.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.17.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.65.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (3.23.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (0.14.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (3.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (24.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-gemini) (0.2.0)\n",
      "Using cached llama_index_core-0.11.22-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.1.6 requires llama-index-core<0.11.0,>=0.10.7, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-embeddings-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-agent-openai 0.2.9 requires llama-index-core<0.11.0,>=0.10.41, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index 0.10.39 requires llama-index-core<0.11.0,>=0.10.39, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-cli 0.1.13 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.1.6 requires llama-index-core<0.11.0,>=0.10.0, but you have llama-index-core 0.11.22 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.11.22\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.26.2)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.11.22)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.10)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.44.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.17.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# パッケージのインストール\n",
    "!pip install llama-index==0.10.39\n",
    "!pip install llama-index-llms-gemini\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_Gf8Rfw2MiG_"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.environ.get(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g9Nyr59eqRUh"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# ログレベルの設定\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Iu7W9lKguoqh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.5.1 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471091186512 on /tmp/llama_index/.locks/models--BAAI--bge-m3/952a9b81c0bfd99800fabf352f69c7ccd46c5e43.lock\n",
      "DEBUG:filelock:Lock 281471091186512 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/952a9b81c0bfd99800fabf352f69c7ccd46c5e43.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 349\n",
      "DEBUG:filelock:Attempting to release lock 281471091186512 on /tmp/llama_index/.locks/models--BAAI--bge-m3/952a9b81c0bfd99800fabf352f69c7ccd46c5e43.lock\n",
      "DEBUG:filelock:Lock 281471091186512 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/952a9b81c0bfd99800fabf352f69c7ccd46c5e43.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471754703568 on /tmp/llama_index/.locks/models--BAAI--bge-m3/1fba91c78a6c8e17227058ab6d4d3acb5d8630a9.lock\n",
      "DEBUG:filelock:Lock 281471754703568 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/1fba91c78a6c8e17227058ab6d4d3acb5d8630a9.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/11\" 200 123\n",
      "DEBUG:filelock:Attempting to release lock 281471754703568 on /tmp/llama_index/.locks/models--BAAI--bge-m3/1fba91c78a6c8e17227058ab6d4d3acb5d8630a9.lock\n",
      "DEBUG:filelock:Lock 281471754703568 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/1fba91c78a6c8e17227058ab6d4d3acb5d8630a9.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/README.md HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471066426000 on /tmp/llama_index/.locks/models--BAAI--bge-m3/e5a320176edd6ee1cfb256e68ee5ac0004de9447.lock\n",
      "DEBUG:filelock:Lock 281471066426000 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/e5a320176edd6ee1cfb256e68ee5ac0004de9447.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/README.md HTTP/11\" 200 15822\n",
      "DEBUG:filelock:Attempting to release lock 281471066426000 on /tmp/llama_index/.locks/models--BAAI--bge-m3/e5a320176edd6ee1cfb256e68ee5ac0004de9447.lock\n",
      "DEBUG:filelock:Lock 281471066426000 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/e5a320176edd6ee1cfb256e68ee5ac0004de9447.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/sentence_bert_config.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471754703376 on /tmp/llama_index/.locks/models--BAAI--bge-m3/0140ba1eac83a3c9b857d64baba91969d988624b.lock\n",
      "DEBUG:filelock:Lock 281471754703376 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/0140ba1eac83a3c9b857d64baba91969d988624b.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/sentence_bert_config.json HTTP/11\" 200 54\n",
      "DEBUG:filelock:Attempting to release lock 281471754703376 on /tmp/llama_index/.locks/models--BAAI--bge-m3/0140ba1eac83a3c9b857d64baba91969d988624b.lock\n",
      "DEBUG:filelock:Lock 281471754703376 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/0140ba1eac83a3c9b857d64baba91969d988624b.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471066426000 on /tmp/llama_index/.locks/models--BAAI--bge-m3/e6eda1c72da8f9dc30fdd9b69c73d35af3b7a7ad.lock\n",
      "DEBUG:filelock:Lock 281471066426000 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/e6eda1c72da8f9dc30fdd9b69c73d35af3b7a7ad.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/config.json HTTP/11\" 200 687\n",
      "DEBUG:filelock:Attempting to release lock 281471066426000 on /tmp/llama_index/.locks/models--BAAI--bge-m3/e6eda1c72da8f9dc30fdd9b69c73d35af3b7a7ad.lock\n",
      "DEBUG:filelock:Lock 281471066426000 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/e6eda1c72da8f9dc30fdd9b69c73d35af3b7a7ad.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/adapter_config.json HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/adapter_config.json HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors.index.json HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/pytorch_model.bin HTTP/11\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471043909520 on /tmp/llama_index/.locks/models--BAAI--bge-m3/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38.lock\n",
      "DEBUG:filelock:Lock 281471043909520 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs-us-1.hf.co:443\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs-us-1.hf.co:443 \"GET /repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731419930&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQxOTkzMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=QBKiD4DtsIfA89LL-68bIoPQrWu1xY68JNRTBdvN3m1JJpWdRu1Nv4T4edGvQqDZcTiZ76eoUEqMS-s2QJBMQC5CGNseETUjju9WfYmxG3uYI5H3HclaRAXHAp3KZstuTal3H4yV9KXbtrPdNXDDgh9bIHpMK44c9A8Idaa5CqpBNn1b~3qwCb6s4cIUVvpt2KUxi2FA1Y8Yf5XXZppIV0iJfu5SVSv3T2mFYIDDa~VyPKPnls7Gpzp2ueufF7WgIeXV4WsKfdFTLW85o4jzIxlF2HSRV43ZJHABu348CpViiq-wu7OKHBhJjcmt50ZkhThSpbR7ugBpSgigK1t-4w__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11\" 200 2271145830\n",
      "DEBUG:filelock:Attempting to release lock 281471043909520 on /tmp/llama_index/.locks/models--BAAI--bge-m3/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38.lock\n",
      "DEBUG:filelock:Lock 281471043909520 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471022739536 on /tmp/llama_index/.locks/models--BAAI--bge-m3/dc69ac559dcba2694012009aaa108c614541789a.lock\n",
      "DEBUG:filelock:Lock 281471022739536 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/dc69ac559dcba2694012009aaa108c614541789a.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/tokenizer_config.json HTTP/11\" 200 444\n",
      "DEBUG:filelock:Attempting to release lock 281471022739536 on /tmp/llama_index/.locks/models--BAAI--bge-m3/dc69ac559dcba2694012009aaa108c614541789a.lock\n",
      "DEBUG:filelock:Lock 281471022739536 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/dc69ac559dcba2694012009aaa108c614541789a.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/sentencepiece.bpe.model HTTP/11\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471022736464 on /tmp/llama_index/.locks/models--BAAI--bge-m3/cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865.lock\n",
      "DEBUG:filelock:Lock 281471022736464 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865.lock\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs-us-1.hf.co:443 \"GET /repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sentencepiece.bpe.model%3B+filename%3D%22sentencepiece.bpe.model%22%3B&Expires=1731418266&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQxODI2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvY2ZjODE0NmFiZTJhMDQ4OGU5ZTJhMGM1NmRlNzk1MmY3YzExYWIwNTllY2ExNDVhMGE3MjdhZmNlMGRiMjg2NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=RU0xQu6KPUXjPUQxmum8RnBIxUOu3rQH-IGob1954VDn8clRUTMWrQw3y-sFqLvWjAsEGRfVJDHdRvE8fp8ZcumYDDK5wkYbIwfzaLUHMoq96TEbcuYk8lLSPda04XnRyyx2STi76LvVjNnLwxzOWwN3o4PJyzWO8FBj~xwH9-9L6WEDW87MK3B8mhjiiKpPrfFFggzRzC6Cnsglil5FEOutw110J2l9aEvRWnIiwxxHXi097v-cL4TnToFyNdnMpWVdLChSt1e6Ku6U7MBX15kU9BvGSGISCioHbAYNa0TqTSe-FSYY9LSrpfcILw-uMcJLZeCrv6oAEZ9yJnwULA__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11\" 200 5069051\n",
      "DEBUG:filelock:Attempting to release lock 281471022736464 on /tmp/llama_index/.locks/models--BAAI--bge-m3/cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865.lock\n",
      "DEBUG:filelock:Lock 281471022736464 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/tokenizer.json HTTP/11\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471064674128 on /tmp/llama_index/.locks/models--BAAI--bge-m3/21106b6d7dab2952c1d496fb21d5dc9db75c28ed361a05f5020bbba27810dd08.lock\n",
      "DEBUG:filelock:Lock 281471064674128 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/21106b6d7dab2952c1d496fb21d5dc9db75c28ed361a05f5020bbba27810dd08.lock\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs-us-1.hf.co:443 \"GET /repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/21106b6d7dab2952c1d496fb21d5dc9db75c28ed361a05f5020bbba27810dd08?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1731417235&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQxNzIzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvMjExMDZiNmQ3ZGFiMjk1MmMxZDQ5NmZiMjFkNWRjOWRiNzVjMjhlZDM2MWEwNWY1MDIwYmJiYTI3ODEwZGQwOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JAhWEKxMn943JQVavQd9UqmvXDRyxaQKdU01a4vQxYQ9-~eoZVIVbzFcdpODMtd8mBarcpdB4gIFbRuB8k2LQXGHYs97kLhDmUvA4tSSVWLKaB1vNjVsuDfvj7RkswnRYrXeVBUu6QR8xwniusdHiJcMBm8v2fFGUPME0PFSAZyCuptyrScpL1l-k7btDWAr91pTOGyR9ldkMZ5p~vAhgsqiDKUUd-yXcGxDYO~gmr8IHqAdl8QQrVmzzzQqVunHrxHETIxLWQce7gp6flv9pr0Cy4XqQn~fGDfwouUhh9I-4ajrt2HICfPLQ7G5oYzyW-p3HIh6vL6PkcgdMIouTw__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11\" 200 17098108\n",
      "DEBUG:filelock:Attempting to release lock 281471064674128 on /tmp/llama_index/.locks/models--BAAI--bge-m3/21106b6d7dab2952c1d496fb21d5dc9db75c28ed361a05f5020bbba27810dd08.lock\n",
      "DEBUG:filelock:Lock 281471064674128 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/21106b6d7dab2952c1d496fb21d5dc9db75c28ed361a05f5020bbba27810dd08.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/added_tokens.json HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/special_tokens_map.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471022735120 on /tmp/llama_index/.locks/models--BAAI--bge-m3/b1879d702821e753ffe4245048eee415d54a9385.lock\n",
      "DEBUG:filelock:Lock 281471022735120 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/b1879d702821e753ffe4245048eee415d54a9385.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/main/special_tokens_map.json HTTP/11\" 200 964\n",
      "DEBUG:filelock:Attempting to release lock 281471022735120 on /tmp/llama_index/.locks/models--BAAI--bge-m3/b1879d702821e753ffe4245048eee415d54a9385.lock\n",
      "DEBUG:filelock:Lock 281471022735120 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/b1879d702821e753ffe4245048eee415d54a9385.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/revision/main HTTP/11\" 200 4533\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/5617a9f61b028005a4858fdac845db406aefb181/1_Pooling/config.json HTTP/11\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471034005264 on /tmp/llama_index/.locks/models--BAAI--bge-m3/9bd85925f325e25246d94c4918dc02ab98f2a1b7.lock\n",
      "DEBUG:filelock:Lock 281471034005264 acquired on /tmp/llama_index/.locks/models--BAAI--bge-m3/9bd85925f325e25246d94c4918dc02ab98f2a1b7.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /BAAI/bge-m3/resolve/5617a9f61b028005a4858fdac845db406aefb181/1_Pooling/config.json HTTP/11\" 200 191\n",
      "DEBUG:filelock:Attempting to release lock 281471034005264 on /tmp/llama_index/.locks/models--BAAI--bge-m3/9bd85925f325e25246d94c4918dc02ab98f2a1b7.lock\n",
      "DEBUG:filelock:Lock 281471034005264 released on /tmp/llama_index/.locks/models--BAAI--bge-m3/9bd85925f325e25246d94c4918dc02ab98f2a1b7.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/11\" 200 4533\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# LLMの準備\n",
    "Settings.llm = Gemini(\n",
    "    model_name=\"models/gemini-1.5-flash\",\n",
    "    safety_settings={\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\" : \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\" : \"BLOCK_NONE\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 埋め込みモデルの準備\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-m3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKqtnf0Gf24g"
   },
   "source": [
    "### LLMのカスタマイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRc4pkscaO0v"
   },
   "source": [
    "### LLMをGemini 1.0 Proに切り替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9QoTPo_aaPqg"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "# LLMの設定\n",
    "Settings.llm = Gemini(\n",
    "    model_name=\"models/gemini-1.0-pro\",\n",
    "    temperature=0.3,\n",
    "    safety_settings={\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\" : \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\" : \"BLOCK_NONE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0CaVlPQrd3_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "富士山\n"
     ]
    }
   ],
   "source": [
    "# LLMの動作確認\n",
    "response = Settings.llm.complete(\"日本一高い山は？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdYDHMmNaE3e"
   },
   "source": [
    "### LLMをGPT-4に切り替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T4IfdXWxtfM"
   },
   "outputs": [],
   "source": [
    "# パッケージのインストール\n",
    "!pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiMQa0Hqy3z9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# 環境変数の準備 (左端の鍵アイコンでOPENAI_API_KEYを設定)\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hyXqsvpx1bi"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# LLMの設定\n",
    "Settings.llm = OpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D5ycJLZybN7"
   },
   "outputs": [],
   "source": [
    "# LLMの動作確認\n",
    "response = Settings.llm.complete(\"日本一高い山は？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaMZ54-tzIRa"
   },
   "source": [
    "### 埋め込みモデルのカスタマイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da6k3oOgbqrl"
   },
   "source": [
    "### 埋め込みモデルをtext-embedding-3-smallに切り替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dlFT0eEybQi"
   },
   "outputs": [],
   "source": [
    "# パッケージのインストール\n",
    "!pip install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3VAiol5ybSb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# 環境変数の準備 (左端の鍵アイコンでOPENAI_API_KEYを設定)\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlfM3kCszUQV"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# 埋め込みモデルの設定\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1H0R54OGzTLU"
   },
   "outputs": [],
   "source": [
    "# 埋め込みモデルの動作確認\n",
    "embeddings = Settings.embed_model.get_text_embedding(\"日本一高い山は？\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA-97fPq1ZUW"
   },
   "source": [
    "### トークナイザーのカスタマイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DQ20mUZm1Xu5"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "import tiktoken\n",
    "\n",
    "# トークナイザーの設定\n",
    "Settings.tokenizer = tiktoken.encoding_for_model(\"gpt-4-turbo\").encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJjZdNgf1qXS"
   },
   "outputs": [],
   "source": [
    "# トークナイザーの動作確認\n",
    "tokens = Settings.tokenizer(\"こんにちは、世界！\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dj1VHcFk0Oee"
   },
   "source": [
    "### テキストスプリッターのカスタマイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Fz4gwTP52_UU"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# テキストスプリッターの設定\n",
    "Settings.text_splitter = SentenceSplitter(\n",
    "    chunk_size=20,  # テスト用に極端に小さくしています\n",
    "    chunk_overlap=0,\n",
    "    paragraph_separator=\"\\n\\n\",  # 段落の区切り文字に\"\\n\\n\"を指定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rsj2QuT82eFd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1章のコンテキスト\\n\\n2章のコンテキスト', '3章のコンテキスト']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分割するテキストの準備\n",
    "text = '''1章のコンテキスト\n",
    "\n",
    "2章のコンテキスト\n",
    "\n",
    "3章のコンテキスト'''\n",
    "\n",
    "# テキストスプリッターの動作確認\n",
    "Settings.text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "t98dDl4hRrZw"
   },
   "outputs": [],
   "source": [
    "# テキストスプリッターをデフォルトに戻す\n",
    "Settings.text_splitter = SentenceSplitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUCRhFz9idAx"
   },
   "source": [
    "### 取得するノード数の調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ApQZoBJguSZ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/README.md HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/sentence_bert_config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/11\" 200 4533\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/revision/main HTTP/11\" 200 4533\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/11\" 200 4533\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/main HTTP/11\" 200 9525\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/discussions?p=0 HTTP/11\" 200 20244\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/refs%2Fpr%2F71 HTTP/11\" 200 10490\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): safetensors-convert.hf.space:443\n",
      "DEBUG:urllib3.connectionpool:https://safetensors-convert.hf.space:443 \"POST /call/run HTTP/11\" 200 47\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): safetensors-convert.hf.space:443\n",
      "DEBUG:urllib3.connectionpool:https://safetensors-convert.hf.space:443 \"GET /call/run/3e9898d005254a19a193720405ae382a HTTP/11\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/main HTTP/11\" 200 9525\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/discussions?p=0 HTTP/11\" 200 20244\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/refs%2Fpr%2F71 HTTP/11\" 200 10490\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/refs%2Fpr%2F71/model.safetensors.index.json HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/refs%2Fpr%2F71/model.safetensors HTTP/11\" 302 0\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# LLMの準備\n",
    "Settings.llm = Gemini(\n",
    "    model_name=\"models/gemini-1.5-flash\",\n",
    "    safety_settings={\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\" : \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\" : \"BLOCK_NONE\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 埋め込みモデルの準備\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-m3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M6TVEQVoi2Fp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.readers.file.base:> [SimpleDirectoryReader] Total files added: 7\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin1.txt\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin2.txt\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin3.txt\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin4.txt\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin5.txt\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin6.txt\n",
      "DEBUG:fsspec.local:open file: /work/gemini_npaka/llamaindex/data/akazukin7.txt\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# ドキュメントの読み込み (dataフォルダにドキュメントを配置しておきます)\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-LfhKuaki2Hr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第1章：ネオン街の影\n",
      "2078年、東京。ネオン街の闇に紛れ、少女アズキはフードを深く被り、路地...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第2章：牢獄の出会い\n",
      "暗い牢獄に閉じ込められたアズキ。絶望に打ちひしがれながらも、彼女は諦めな...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第3章：情報収集\n",
      "ネオン街の裏社会に潜伏するアズキとオオカミ。彼らは帝国の秘密情報を収集するた...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第4章：裏切り\n",
      "ある日、オオカミの裏切りが発覚する。彼は帝国に情報を売っていたのだ。\n",
      "アズキは...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第5章：決戦\n",
      "ついに、アズキとオオカミは帝国の本拠地へ潜入する。そこで、彼らは帝国の恐るべき計...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第6章：希望の光\n",
      "激しい戦いの末、アズキとオオカミはシステムを破壊することに成功する。帝国は崩...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 第7章：新たな旅\n",
      "街に平和が訪れた数年後、アズキは新たな旅に出る。\n",
      "彼女は世界中を旅し、他の抑...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# インデックスの作成\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VTx_Crt5i2Ji"
   },
   "outputs": [],
   "source": [
    "# クエリエンジンの作成\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jz2xwJi0i2L1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
      "> [Node e477f34b-94e7-4b45-9278-f05193540b5f] [Similarity score:             0.544501] 第1章：ネオン街の影\n",
      "2078年、東京。ネオン街の闇に紛れ、少女アズキはフードを深く被り、路地裏を疾走していた。彼女は16歳、ハッカー集団「紅ずきん」の一員だ。\n",
      "アズキのターゲットは、企業連合「...\n",
      "> [Node 1b130908-8383-4dd3-a97a-6d1847943b5e] [Similarity score:             0.510709] 第2章：牢獄の出会い\n",
      "暗い牢獄に閉じ込められたアズキ。絶望に打ちひしがれながらも、彼女は諦めなかった。脱出する方法を探るアズキの前に、謎めいた青年が現れる。\n",
      "青年はハッカー「オオカミ」と呼ばれ、...\n",
      "> [Node 5cbe7dee-07ce-44af-a673-fd7c353d3376] [Similarity score:             0.471858] 第7章：新たな旅\n",
      "街に平和が訪れた数年後、アズキは新たな旅に出る。\n",
      "彼女は世界中を旅し、他の抑圧された人々を助け、自由と正義のために戦い続ける。\n",
      "アズキは、ネオン街の影から生まれ、希望の光となっ...\n",
      "> [Node a4ba942c-e46e-4d9d-a7b1-423ccdb80620] [Similarity score:             0.458938] 第3章：情報収集\n",
      "ネオン街の裏社会に潜伏するアズキとオオカミ。彼らは帝国の秘密情報を収集するために、様々なハッキング作戦を実行していく。\n",
      "しかし、帝国も黙っていない。アズキたちを追跡し、次々と罠...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アズキは16歳です。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 質問応答\n",
    "print(query_engine.query(\"アズキの年齢は？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLSECa4LiYjh"
   },
   "source": [
    "### Rerankerの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m4Xnbkn8xSZ7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-postprocessor-flag-embedding-reranker in /usr/local/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/site-packages (from llama-index-postprocessor-flag-embedding-reranker) (0.11.22)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2024.10.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.17.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.23.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (24.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting FlagEmbedding\n",
      "  Using cached FlagEmbedding-1.3.2-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/site-packages (from FlagEmbedding) (2.5.1)\n",
      "Collecting transformers==4.44.2 (from FlagEmbedding)\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets==2.19.0 (from FlagEmbedding)\n",
      "  Using cached datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate>=0.20.1 (from FlagEmbedding)\n",
      "  Using cached accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/site-packages (from FlagEmbedding) (3.2.1)\n",
      "Collecting peft (from FlagEmbedding)\n",
      "  Using cached peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ir-datasets (from FlagEmbedding)\n",
      "  Using cached ir_datasets-0.5.9-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/site-packages (from FlagEmbedding) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/site-packages (from FlagEmbedding) (4.25.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (1.26.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached pyarrow-18.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.3 kB)\n",
      "Collecting pyarrow-hotfix (from datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (4.67.0)\n",
      "Collecting xxhash (from datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from datasets==2.19.0->FlagEmbedding) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers==4.44.2->FlagEmbedding) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/site-packages (from transformers==4.44.2->FlagEmbedding) (0.4.5)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2->FlagEmbedding)\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate>=0.20.1->FlagEmbedding) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->FlagEmbedding) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->FlagEmbedding) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->FlagEmbedding) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->FlagEmbedding) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/site-packages (from ir-datasets->FlagEmbedding) (4.12.3)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached inscriptis-2.5.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting lxml>=4.5.2 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached lxml-5.3.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.8 kB)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached lz4-4.3.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.7 kB)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached warc3_wet_clueweb09-0.2.5-py3-none-any.whl\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached zlib_state-0.1.9.tar.gz (9.5 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached ijson-3.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (21 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding)\n",
      "  Using cached unlzw3-0.2.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from sentence-transformers->FlagEmbedding) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from sentence-transformers->FlagEmbedding) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from sentence-transformers->FlagEmbedding) (10.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding) (2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding) (2024.8.30)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding)\n",
      "  Using cached cbor-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (3.0.2)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.19.0->FlagEmbedding)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==2.19.0->FlagEmbedding) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==2.19.0->FlagEmbedding) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->datasets==2.19.0->FlagEmbedding) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->FlagEmbedding) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->FlagEmbedding) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.0->FlagEmbedding) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.19.0->FlagEmbedding) (0.2.0)\n",
      "Using cached datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Using cached accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Using cached ir_datasets-0.5.9-py3-none-any.whl (347 kB)\n",
      "Using cached peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached ijson-3.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (121 kB)\n",
      "Using cached inscriptis-2.5.0-py3-none-any.whl (45 kB)\n",
      "Using cached lxml-5.3.0-cp311-cp311-manylinux_2_28_aarch64.whl (4.8 MB)\n",
      "Using cached lz4-4.3.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.2 MB)\n",
      "Using cached pyarrow-18.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (38.6 MB)\n",
      "Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.6 MB)\n",
      "Using cached trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Using cached unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
      "Using cached warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (221 kB)\n",
      "Building wheels for collected packages: zlib-state\n",
      "  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zlib-state: filename=zlib_state-0.1.9-cp311-cp311-linux_aarch64.whl size=21398 sha256=b102833f8e8161f4c92184c6ad3772b39f6ee6f112ab6f164e14eae903cb60ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/2b/f5/832b7f969fcfc2077db173572af89254d7e87f5918cb8fe486\n",
      "Successfully built zlib-state\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, xxhash, unlzw3, trec-car-tools, pyarrow-hotfix, pyarrow, lz4, lxml, fsspec, dill, multiprocess, inscriptis, tokenizers, ir-datasets, accelerate, transformers, datasets, peft, FlagEmbedding\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.2\n",
      "    Uninstalling transformers-4.46.2:\n",
      "      Successfully uninstalled transformers-4.46.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-agent-openai 0.2.9 requires llama-index-core<0.11.0,>=0.10.41, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index 0.10.39 requires llama-index-core<0.11.0,>=0.10.39, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-cli 0.1.13 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.22 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.1.6 requires llama-index-core<0.11.0,>=0.10.0, but you have llama-index-core 0.11.22 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed FlagEmbedding-1.3.2 accelerate-1.1.1 cbor-1.0.0 datasets-2.19.0 dill-0.3.8 fsspec-2024.3.1 ijson-3.3.0 inscriptis-2.5.0 ir-datasets-0.5.9 lxml-5.3.0 lz4-4.3.3 multiprocess-0.70.16 peft-0.13.2 pyarrow-18.0.0 pyarrow-hotfix-0.6 tokenizers-0.19.1 transformers-4.44.2 trec-car-tools-2.6 unlzw3-0.2.2 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 xxhash-3.5.0 zlib-state-0.1.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Rerankerパッケージのインストール\n",
    "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
    "!pip install FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gWI4xlWfxScG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-reranker-v2-m3/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-reranker-v2-m3/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-reranker-v2-m3/resolve/main/model.safetensors HTTP/11\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 281471022791120 on /root/.cache/huggingface/hub/.locks/models--BAAI--bge-reranker-v2-m3/d9e3e081faff1eefb84019509b2f5558fd74c1a05a2c7db22f74174fcedb5286.lock\n",
      "DEBUG:filelock:Lock 281471022791120 acquired on /root/.cache/huggingface/hub/.locks/models--BAAI--bge-reranker-v2-m3/d9e3e081faff1eefb84019509b2f5558fd74c1a05a2c7db22f74174fcedb5286.lock\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs-us-1.hf.co:443 \"GET /repos/fb/3f/fb3fe87288ff7667a58d0dac0de359a1ea242a8cb977a35823603c68613285dc/d9e3e081faff1eefb84019509b2f5558fd74c1a05a2c7db22f74174fcedb5286?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731420148&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQyMDE0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZiLzNmL2ZiM2ZlODcyODhmZjc2NjdhNThkMGRhYzBkZTM1OWExZWEyNDJhOGNiOTc3YTM1ODIzNjAzYzY4NjEzMjg1ZGMvZDllM2UwODFmYWZmMWVlZmI4NDAxOTUwOWIyZjU1NThmZDc0YzFhMDVhMmM3ZGIyMmY3NDE3NGZjZWRiNTI4Nj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=jovuValO9TUBibQAmXXSYYYWLBDkWsaGr0TsKnaqR3fAprHQXAsg~NiP~U56OtY-cCgin~ZrXkOq~GvcWdouq8iaZE0XbtM66sTOOPEkx5d7AFIdI2zUPp~5DV5y~I6xw7aV2sYvaj5ir5UcFaHC5nNd9GYxlR3RjTV3opZ0vlXHqiX3qlYxOoBffvgWZ8HGdDpHQWAsz1wDjjvyrSwxk5COQOIbir3IOSuaR6Xw~vPHXOVU~5NVPflI98VnpJ~RW-4nPGcQAa1q-dVghY66NzuYbjdZE-km3Xqy4IJXCUTY0~y5Lue0RnYgg9TZ6jpTWynJYesP3EdOZpWdr28agA__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11\" 206 247320172\n",
      "DEBUG:filelock:Attempting to release lock 281471022791120 on /root/.cache/huggingface/hub/.locks/models--BAAI--bge-reranker-v2-m3/d9e3e081faff1eefb84019509b2f5558fd74c1a05a2c7db22f74174fcedb5286.lock\n",
      "DEBUG:filelock:Lock 281471022791120 released on /root/.cache/huggingface/hub/.locks/models--BAAI--bge-reranker-v2-m3/d9e3e081faff1eefb84019509b2f5558fd74c1a05a2c7db22f74174fcedb5286.lock\n"
     ]
    }
   ],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "# Rerankerの準備\n",
    "rerank = FlagEmbeddingReranker(\n",
    "    model=\"BAAI/bge-reranker-v2-m3\",\n",
    "    use_fp16=True,\n",
    "    top_n=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vY_0XlLrxSeC"
   },
   "outputs": [],
   "source": [
    "# クエリエンジンの準備\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=4,\n",
    "    node_postprocessors=[rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7ndMauqmxSf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
      "> [Node e477f34b-94e7-4b45-9278-f05193540b5f] [Similarity score:             0.544501] 第1章：ネオン街の影\n",
      "2078年、東京。ネオン街の闇に紛れ、少女アズキはフードを深く被り、路地裏を疾走していた。彼女は16歳、ハッカー集団「紅ずきん」の一員だ。\n",
      "アズキのターゲットは、企業連合「...\n",
      "> [Node 1b130908-8383-4dd3-a97a-6d1847943b5e] [Similarity score:             0.510709] 第2章：牢獄の出会い\n",
      "暗い牢獄に閉じ込められたアズキ。絶望に打ちひしがれながらも、彼女は諦めなかった。脱出する方法を探るアズキの前に、謎めいた青年が現れる。\n",
      "青年はハッカー「オオカミ」と呼ばれ、...\n",
      "> [Node 5cbe7dee-07ce-44af-a673-fd7c353d3376] [Similarity score:             0.471858] 第7章：新たな旅\n",
      "街に平和が訪れた数年後、アズキは新たな旅に出る。\n",
      "彼女は世界中を旅し、他の抑圧された人々を助け、自由と正義のために戦い続ける。\n",
      "アズキは、ネオン街の影から生まれ、希望の光となっ...\n",
      "> [Node a4ba942c-e46e-4d9d-a7b1-423ccdb80620] [Similarity score:             0.458938] 第3章：情報収集\n",
      "ネオン街の裏社会に潜伏するアズキとオオカミ。彼らは帝国の秘密情報を収集するために、様々なハッキング作戦を実行していく。\n",
      "しかし、帝国も黙っていない。アズキたちを追跡し、次々と罠...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 874.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アズキは16歳です。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 質問応答\n",
    "response = query_engine.query(\"アズキの年齢は？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "McHCyvCXxShr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1章：ネオン街の影\n",
      "2078年、東京。ネオン街の闇に紛れ、少女アズキはフードを深く被り、路地裏を疾走していた。彼女は16歳、ハッカー集団「紅ずきん」の一員だ。\n",
      "アズキのターゲットは、企業連合「帝国」の秘密情報。帝国は街を支配し、人々を搾取していた。アズキたちは、そんな帝国に立ち向かうレジスタンスの尖兵だった。\n",
      "しかし、アズキは罠に嵌められた。背後から襲い掛かる帝国の警備隊。アズキは必死に逃げ回るが、追いつかれ、捕らわれてしまう。\n",
      "--\n",
      "第7章：新たな旅\n",
      "街に平和が訪れた数年後、アズキは新たな旅に出る。\n",
      "彼女は世界中を旅し、他の抑圧された人々を助け、自由と正義のために戦い続ける。\n",
      "アズキは、ネオン街の影から生まれ、希望の光となって世界を照らす存在となった。\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# 取得したノードの確認\n",
    "for node in response.source_nodes:\n",
    "     print(node.get_text())\n",
    "     print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7kGxNqACA40X9ZGzyyojG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf_XcjXD89hw"
   },
   "source": [
    "### LlamaIndexの前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkPbwp6-ploX"
   },
   "outputs": [],
   "source": [
    "# パッケージのインストール\n",
    "!pip install llama-index==0.10.39\n",
    "!pip install llama-index-llms-gemini\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_Gf8Rfw2MiG_"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.environ.get(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g9Nyr59eqRUh"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# ログレベルの設定\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "csQ-xJmMqmM6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.5.1 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/README.md HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/sentence_bert_config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/revision/main HTTP/11\" 200 4533\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/11\" 200 4533\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# LLMの準備\n",
    "Settings.llm = Gemini(\n",
    "    model_name=\"models/gemini-1.5-flash\",\n",
    "    safety_settings={\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\" : \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\" : \"BLOCK_NONE\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 埋め込みモデルの準備\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-m3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi1fnUzvgf_c"
   },
   "source": [
    "### Webページへの質問応答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VSHT5qF-l9_g",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-readers-web\n",
      "  Downloading llama_index_readers_web-0.2.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-web) (3.10.10)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-web) (4.12.3)\n",
      "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web)\n",
      "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting html2text<2025.0.0,>=2024.2.26 (from llama-index-readers-web)\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-web) (0.11.22)\n",
      "Collecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web)\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
      "  Downloading playwright-1.48.0-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-web) (2.32.3)\n",
      "Collecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web)\n",
      "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\n",
      "  Downloading spider-client-0.0.27.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.1.0 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-web) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web) (2.6)\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/site-packages (from chromedriver-autoinstaller<0.7.0,>=0.6.3->llama-index-readers-web) (24.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.16.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.11/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (5.3.0)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.11/site-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.1.1)\n",
      "Collecting pyee==12.0.0 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
      "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (2024.8.30)\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/site-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from feedfinder2>=0.0.4->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (2.23.4)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (3.16.1)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.0.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (0.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (3.23.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-web) (0.14.0)\n",
      "Downloading llama_index_readers_web-0.2.4-py3-none-any.whl (76 kB)\n",
      "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading playwright-1.48.0-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (37.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyee-12.0.0-py3-none-any.whl (14 kB)\n",
      "Downloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
      "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: html2text, tinysegmenter, spider-client, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for html2text (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33110 sha256=0fa4a4e8691d81f8a1b4200012824e267e0aec17a0897aca540a9e8a81dd283d\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/58/7c/d9c8c4d924a1ac2b621add1b2c1d30b639629a33cfdfde6a45\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=7d459979cbb27d647003e1b8129ba01a3c1297cb45b5aadc5a1623e62cb237fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/f8/cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n",
      "  Building wheel for spider-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spider-client: filename=spider_client-0.0.27-py3-none-any.whl size=5976 sha256=b5f08316c31836bddad1774fcac4c57e00388cc0d0f94be4e4943a66bd30f5a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/73/17/fab0356e5eec634ef9f9d0bdec011743f48ef380ee7307804f\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3339 sha256=0041cb98455a56cb615c46e1d22b9911969af14d8093f743f50607224addf52b\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/d5/72/9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=51406190c25689d6acc29a5a17cc1928bcb11d57aebfc2124475ec2bf5a2960f\n",
      "  Stored in directory: /root/.cache/pip/wheels/3a/a1/46/8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=9bed7424d0eb204f5989d179d52ffc368b6edf9bd4004b6c5f597f5d5b929282\n",
      "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built html2text tinysegmenter spider-client feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sortedcontainers, sgmllib3k, jieba3k, wsproto, pysocks, pyee, outcome, html2text, feedparser, cssselect, chromedriver-autoinstaller, trio, spider-client, requests-file, playwright, feedfinder2, trio-websocket, tldextract, selenium, newspaper3k, llama-index-readers-web\n",
      "Successfully installed chromedriver-autoinstaller-0.6.4 cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 html2text-2024.2.26 jieba3k-0.35.1 llama-index-readers-web-0.2.4 newspaper3k-0.2.8 outcome-1.3.0.post0 playwright-1.48.0 pyee-12.0.0 pysocks-1.7.1 requests-file-2.1.0 selenium-4.26.1 sgmllib3k-1.0.0 sortedcontainers-2.4.0 spider-client-0.0.27 tinysegmenter-0.3 tldextract-5.1.3 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# パッケージのインストール\n",
    "!pip install llama-index-readers-web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SxclTRjlj-_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): deepmind.google:443\n",
      "DEBUG:urllib3.connectionpool:https://deepmind.google:443 \"GET /about/ HTTP/11\" 200 None\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.web import BeautifulSoupWebReader\n",
    "\n",
    "# データローダーの準備\n",
    "reader = BeautifulSoupWebReader()\n",
    "\n",
    "# ドキュメントの読み込み\n",
    "documents = reader.load_data(urls=[\"https://deepmind.google/about/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='https://deepmind.google/about/', embedding=None, metadata={'URL': 'https://deepmind.google/about/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='\\n\\n\\n\\n\\nAbout - Google DeepMind\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Jump to Content\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogle\\n\\n\\n\\n\\nDeepMind\\n\\n\\n\\n\\n\\n\\nSearch...\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\nClose\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogle\\n\\n\\n\\n\\nDeepMind\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          About\\n          \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Learn about Google DeepMind\\n          \\n          \\n        \\n\\n — Our mission is to build AI responsibly to benefit humanity\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Responsibility & Safety\\n          \\n          \\n        \\n\\n — We want AI to benefit the world, so we must be thoughtful about how it’s built and used\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Education\\n          \\n          \\n        \\n\\n — Our vision is to help make the AI ecosystem more representative of society\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Careers\\n          \\n          \\n        \\n\\n — Many disciplines, one common goal\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Research\\n          \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          View Research\\n          \\n          \\n        \\n\\n — We work on some of the most complex and interesting challenges in AI.\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Breakthroughs\\n          \\n          \\n        \\n\\n — Explore some of the biggest innovations in AI\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Publications\\n          \\n          \\n        \\n\\n — Explore a selection of our recent research\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Technologies\\n          \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          View Technologies\\n          \\n          \\n        \\n\\n — Solving the world’s most complex challenges\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Gemini\\n          \\n          \\n\\n\\n\\n\\n — The most general and capable AI models we\\'ve ever built\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Gemini models\\n          \\n          \\n        \\n\\n — The Gemini family of models are the most general and capable AI models we\\'ve ever built.\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Ultra\\n          \\n          \\n        \\n\\n — Our largest model for highly complex tasks.\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Pro\\n          \\n          \\n        \\n\\n — Our best model for general performance across a wide range of tasks.\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Flash\\n          \\n          \\n        \\n\\n — Our lightweight model, optimized for speed and efficiency.\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Nano\\n          \\n          \\n        \\n\\n — Our most efficient model for on-device tasks.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Project Astra\\n          \\n          \\n        \\n\\n — A universal AI agent that is helpful in everyday life\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Imagen\\n          \\n          \\n        \\n\\n — Our highest quality text-to-image model\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Veo\\n          \\n          \\n        \\n\\n — Our most capable generative video model\\n          \\n\\n\\n\\n\\n\\n\\n\\n          AlphaFold\\n          \\n          \\n\\n\\n\\n\\n — Accelerating breakthroughs in biology with AI\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Overview\\n          \\n          \\n        \\n\\n\\n\\n\\n\\n\\n\\n          Impact stories\\n          \\n          \\n        \\n\\n\\n\\n\\n\\n\\n\\n          AlphaFold Database\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          AlphaFold Server\\n          \\n          \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          SynthID\\n          \\n          \\n        \\n\\n — Identifying AI-generated content\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Discover\\n          \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          View Discover\\n          \\n          \\n        \\n\\n — Discover our latest breakthroughs and see how we’re shaping the future\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Blog\\n          \\n          \\n        \\n\\n — Discover our latest AI breakthroughs, projects, and updates\\n          \\n\\n\\n\\n\\n\\n\\n\\n          Events\\n          \\n          \\n        \\n\\n — Meet our team and learn more about our research\\n          \\n\\n\\n\\n\\n\\n\\n\\n          The Podcast\\n          \\n          \\n        \\n\\n — Uncover the extraordinary ways AI is transforming our world\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch...\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\nClose\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Learn about Google DeepMind\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Responsibility & Safety\\n          \\n          \\n        \\n\\n — We want AI to benefit the world, so we must be thoughtful about how it’s built and used\\n          \\n\\n\\n\\n\\n\\n\\n          Education\\n          \\n          \\n        \\n\\n — Our vision is to help make the AI ecosystem more representative of society\\n          \\n\\n\\n\\n\\n\\n\\n          Careers\\n          \\n          \\n        \\n\\n — Many disciplines, one common goal\\n          \\n\\n\\n\\n\\n\\nLatest posts\\n\\n\\n\\n\\n\\n\\n\\nPushing the frontiers of audio generation\\n30 October 2024\\n\\n\\n\\n\\n\\n\\n\\n\\nNew generative AI tools open the doors of music creation\\n23 October 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          View Research\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Breakthroughs\\n          \\n          \\n        \\n\\n — Explore some of the biggest innovations in AI\\n          \\n\\n\\n\\n\\n\\n\\n          Publications\\n          \\n          \\n        \\n\\n — Explore a selection of our recent research\\n          \\n\\n\\n\\n\\n\\nLatest research posts\\n\\n\\n\\n\\n\\n\\n\\nHow AlphaChip transformed computer chip design\\n26 September 2024\\n\\n\\n\\n\\n\\n\\n\\n\\nOur latest advances in robot dexterity\\n12 September 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          View Technologies\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Gemini\\n          \\n          \\n        \\n\\n — The most general and capable AI models we\\'ve ever built\\n          \\n\\n\\n\\n\\n\\n\\n          Project Astra\\n          \\n          \\n        \\n\\n — A universal AI agent that is helpful in everyday life\\n          \\n\\n\\n\\n\\n\\n\\n          Imagen\\n          \\n          \\n        \\n\\n — Our highest quality text-to-image model\\n          \\n\\n\\n\\n\\n\\n\\n          Veo\\n          \\n          \\n        \\n\\n — Our most capable generative video model\\n          \\n\\n\\n\\n\\n\\n\\n          AlphaFold\\n          \\n          \\n        \\n\\n — Accelerating breakthroughs in biology with AI\\n          \\n\\n\\n\\n\\n\\n\\n          SynthID\\n          \\n          \\n        \\n\\n — Identifying AI-generated content\\n          \\n\\n\\n\\n\\n\\nLatest technology posts\\n\\n\\n\\n\\n\\n\\n\\nPushing the frontiers of audio generation\\n30 October 2024\\n\\n\\n\\n\\n\\n\\n\\n\\nNew generative AI tools open the doors of music creation\\n23 October 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          View Discover\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Blog\\n          \\n          \\n        \\n\\n — Discover our latest AI breakthroughs, projects, and updates\\n          \\n\\n\\n\\n\\n\\n\\n          Events\\n          \\n          \\n        \\n\\n — Meet our team and learn more about our research\\n          \\n\\n\\n\\n\\n\\n\\n          The Podcast\\n          \\n          \\n        \\n\\n — Uncover the extraordinary ways AI is transforming our world\\n          \\n\\n\\n\\n\\n\\nLatest posts\\n\\n\\n\\n\\n\\n\\n\\nPushing the frontiers of audio generation\\n30 October 2024\\n\\n\\n\\n\\n\\n\\n\\n\\nNew generative AI tools open the doors of music creation\\n23 October 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur mission\\nBuild AI responsibly to benefit humanity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur vision\\n\\nOur journey\\n\\nOur technologies\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur visionWe live in an exciting time when AI research and technology are delivering extraordinary advances.In the coming years, AI — and ultimately artificial general intelligence (AGI) — has the potential to drive one of the greatest transformations in history.We’re a team of scientists, engineers, ethicists and more, working to build the next generation of AI systems safely and responsibly.By solving some of the hardest scientific and engineering challenges of our time, we’re working to create breakthrough technologies that could advance science, transform work, serve diverse communities — and improve billions of people’s lives.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n“\\nAI has the potential to be one of the most important and beneficial technologies ever invented.\\n\\nDemis HassabisCo-founder and CEO, Google DeepMind\\n\\n\\n\\n\\nOur journeyGoogle DeepMind brings together two of the world’s leading AI labs — Google Brain and DeepMind — into a single, focused team led by our CEO Demis Hassabis. Over the last decade, the two teams were responsible for some of the biggest research breakthroughs in AI, many of which underpin the flourishing AI industry we see today.DeepMind started in 2010, with an interdisciplinary approach to building general AI systems. The research lab brought together new ideas and advances in machine learning, neuroscience, engineering, mathematics, simulation and computing infrastructure, along with new ways of organizing scientific endeavors.The lab achieved early success by pioneering the field of deep reinforcement learning - a combination of deep learning and reinforcement learning - and using games to test its systems. One of its early breakthroughs was a program called DQN, which learned to play 49 different Atari games from scratch just by observing the raw pixels on the screen and being told to maximize the score.In 2015, DeepMind unveiled AlphaGo, the first computer program to defeat a Go world champion. Go was a long-standing grand challenge in AI and AlphaGo’s landmark achievement was considered a decade ahead of its time. AlphaGo inspired a new era of AI systems and its successors, AlphaZero and MuZero, are increasingly general and able to solve many different games as well as complex real-world problems, from compressing YouTube videos to discovering new more efficient computer algorithms.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEpisode 1\\nUnreasonably Effective AI with Demis Hassabis\\n\\n\\n\\n              Watch on YouTube\\n              \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEpisode 2\\nAI: Your New Creative Muse? with Douglas Eck\\n\\n\\n\\n              Watch on YouTube\\n              \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEpisode 3\\nAI Safety... Ok Doomer: with Anca Dragan\\n\\n\\n\\n              Watch on YouTube\\n              \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\nAfter the success of AlphaGo, the DeepMind team sought out increasingly complex games that capture different elements of intelligence. In 2019 we demonstrated AlphaStar, the first AI system to defeat a top professional player at StarCraft II, considered to be one of the most challenging Real-Time Strategy (RTS) games and one of the longest-played e-sports of all time.The team also invented WaveNet, a realistic text-to-speech model that was used as the voice of the Google Assistant and introduced a lot of the technology used in Generative AI systems today.Then in 2020, DeepMind launched AlphaFold, an AI system that accurately predicts 3D models of protein structures — catalyzing a new wave of progress in biology. Other breakthroughs include writing computer programs at a competitive level with AlphaCode, discovering faster sorting algorithms with AlphaDev, advancing weather predictions with unparalleled accuracy, and controlling plasma in nuclear fusion reactors.Google Brain started in 2011 at X, the moonshot factory, exploring how modern AI could transform Google’s products and services, and furthering its mission to organize the world\\'s information and make it universally accessible and useful.Today, Google’s infrastructure runs on Google Brain’s research breakthroughs, including open source software like JAX and TensorFlow, sequence-to-sequence learning for machine translation, and complex machine learning systems to rank search results, and serve and organize online ads.\\n\\nExplore our researchWe work on some of the most complex and interesting challenges in AI.\\n\\n\\n\\n\\n\\n\\n\\nAlphaProteo\\nNew AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlphaGeometry\\nBreakthrough AI performance solving complex math problems\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlphaMissense\\nNew AI tool classifies the effects of 71 million ‘missense’ mutations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nView Research\\n\\n\\nIn 2017, Brain invented the Transformer architecture, an elegant system of neural networks that underpin almost all large language models and revolutionized the field of AI. Over the years, Brain has continued to push what is possible with Transformers, from open-sourcing as BERT to improving Google Searches. Models like LaMDA showed the potential for these types of AI systems to be even more conversational, while the PaLM family of models showed how broadly capable these models can be. They have also ushered in a new era of consumer AI systems, including Google’s collaborative experiment Bard.The team has also advanced the state-of-the-art in robotics by using a large language model in a robotics system with PaLM-SayCan, and the creation of a more generalized visual-language-action model with RT-2. Brain also pioneered the use of machine learning in the creative process with Magenta and text-to-image generation models like Imagen. The team’s work on the Universal Speech Model enables better understanding of more spoken languages around the world, while initiatives like Project Euphonia improve communication for people with speech impairments.Now, as Google DeepMind, our world-class talent is harnessing our unparalleled computing infrastructure to create the next wave of research breakthroughs and transformative products. Guided by the scientific method and with a holistic approach to responsibility and safety, we’re working to ensure AI benefits everyone and helps solve the biggest challenges facing humanity.\\n\\n\\n\\nExplore our breakthrough technologiesOur next generation AI systems are solving some of the hardest scientific and engineering challenges of our time.\\n\\n\\n\\n\\n\\n\\n\\nGemini\\nThe most general and capable AI models we\\'ve ever built.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVeo\\nOur most capable generative video model.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImagen 3\\nOur highest quality text-to-image model.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nView all technologies\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nResponsibility & Safety\\nWe help anticipate a broad spectrum of AI-related risks, explore ways of preventing them from happening, and find ways to address them if they do.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI Principles\\nWhile we are optimistic about the potential of AI, we recognize that advanced technologies can raise important challenges that must be addressed clearly, thoughtfully, and affirmatively.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Explore our other teams and product areas\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  Google AI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  Google AI for Developers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  Gemini\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  Google Cloud\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  Google Labs\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter links\\n\\n\\n\\nFollow us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout Google DeepMind\\n\\n\\nResponsibility & Safety\\n\\n\\nResearch\\n\\n\\nTechnologies\\n\\n\\nBlog\\n\\n\\nCareers\\n\\n\\n\\n\\n\\n\\n\\nLearn more\\n\\n\\n\\n\\n\\n\\n\\n\\nGemini\\n\\n\\nVeo\\n\\n\\nImagen 3\\n\\n\\nSynthID\\n\\n\\n\\n\\n\\n\\n                    Sign up for updates on our latest innovations\\n                  \\n\\n\\n\\nEmail address\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlease enter a valid email (e.g., \"name@example.com\")\\n\\n\\n\\n\\nI accept Google\\'s Terms and Conditions and acknowledge that my information will be used in accordance with Google\\'s Privacy Policy.\\nSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout Google\\n\\n\\nGoogle products\\n\\n\\nPrivacy\\n\\n\\nTerms\\n\\n\\nCookies management controls\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Jag5dSEvmoJi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: About - Google DeepMind\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Publications\n",
      "          \n",
      "          \n",
      "        \n",
      "\n",
      " —...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Episode 1\n",
      "Unreasonably Effective AI with Demis ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Imagen 3\n",
      "Our highest quality text-to-image mode...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c27fdae84664c40ac51ddfdf789fdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# インデックスとクエリエンジンの準備\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CrXiXQx4nnpL"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4943468afe24eaeb1aca333df4c6d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node 75f1a3dc-d660-4524-976a-afe560edbc2e] [Similarity score:             0.662953] About - Google DeepMind\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Jump to Content\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "G...\n",
      "> [Node 3fe0dc64-8069-493e-afa3-5f4f799010fc] [Similarity score:             0.657381] Episode 1\n",
      "Unreasonably Effective AI with Demis Hassabis\n",
      "\n",
      "\n",
      "\n",
      "              Watch on YouTube\n",
      "       ...\n",
      "Google DeepMindは、AIの分野で大きな進歩を遂げてきました。AlphaGoで囲碁の世界チャンピオンを破ったことで有名になり、その後もStarCraft IIでプロゲーマーを破るAlphaStar、タンパク質の3次元構造を予測するAlphaFoldなど、数々の画期的な成果を上げてきました。また、Google Assistantの音声合成モデルWaveNetや、AIによるプログラム作成システムAlphaCode、高速なソートアルゴリズムを発見したAlphaDevなど、様々な分野で革新的な技術を生み出しています。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 質問応答\n",
    "response = query_engine.query(\"Google DeepMindの歴史について教えてください\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wL-FfZDW4vK"
   },
   "source": [
    "### Youtube動画への質問応答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UxhW_y2Sou4S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-hub-youtube-transcript\n",
      "  Downloading llama-hub-youtube-transcript-0.0.1.tar.gz (3.4 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting requests-html (from llama-hub-youtube-transcript)\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from llama-hub-youtube-transcript) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->llama-hub-youtube-transcript) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->llama-hub-youtube-transcript) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->llama-hub-youtube-transcript) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->llama-hub-youtube-transcript) (2024.8.30)\n",
      "Collecting pyquery (from requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fake-useragent (from requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting parse (from requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting bs4 (from requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting w3lib (from requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting importlib-metadata>=1.4 (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript) (4.67.0)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->llama-hub-youtube-transcript)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading websockets-10.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/site-packages (from bs4->requests-html->llama-hub-youtube-transcript) (4.12.3)\n",
      "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.11/site-packages (from pyquery->requests-html->llama-hub-youtube-transcript) (5.3.0)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/site-packages (from pyquery->requests-html->llama-hub-youtube-transcript) (1.2.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4->bs4->requests-html->llama-hub-youtube-transcript) (2.6)\n",
      "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\n",
      "Downloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading websockets-10.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (108 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Building wheels for collected packages: llama-hub-youtube-transcript\n",
      "  Building wheel for llama-hub-youtube-transcript (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-hub-youtube-transcript: filename=llama_hub_youtube_transcript-0.0.1-py3-none-any.whl size=2949 sha256=6cb4afdde96b4e177d50b3b29747d913146bf6c6ed1227cd25ede83aa26837fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/76/0a/62182eca43ec70bb200cab0f7630b7a6de3f95be70bd12a5b6\n",
      "Successfully built llama-hub-youtube-transcript\n",
      "Installing collected packages: parse, fake-useragent, appdirs, zipp, websockets, w3lib, urllib3, pyquery, pyee, importlib-metadata, bs4, pyppeteer, requests-html, llama-hub-youtube-transcript\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: pyee\n",
      "    Found existing installation: pyee 12.0.0\n",
      "    Uninstalling pyee-12.0.0:\n",
      "      Successfully uninstalled pyee-12.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "playwright 1.48.0 requires pyee==12.0.0, but you have pyee 11.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 bs4-0.0.2 fake-useragent-1.5.1 importlib-metadata-8.5.0 llama-hub-youtube-transcript-0.0.1 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 urllib3-1.26.20 w3lib-2.2.1 websockets-10.4 zipp-3.20.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-readers-youtube-transcript\n",
      "  Downloading llama_index_readers_youtube_transcript-0.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/site-packages (from llama-index-readers-youtube-transcript) (0.11.22)\n",
      "Collecting youtube-transcript-api>=0.5.0 (from llama-index-readers-youtube-transcript)\n",
      "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.17.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (3.23.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (24.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-youtube-transcript) (0.2.0)\n",
      "Downloading llama_index_readers_youtube_transcript-0.2.0-py3-none-any.whl (3.6 kB)\n",
      "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: youtube-transcript-api, llama-index-readers-youtube-transcript\n",
      "Successfully installed llama-index-readers-youtube-transcript-0.2.0 youtube-transcript-api-0.6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# パッケージのインストール\n",
    "!pip install llama-hub-youtube-transcript\n",
    "!pip install llama-index-readers-youtube-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qly4c2ZUpDUW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n",
      "DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /watch?v=jV1vkHv4zq8 HTTP/11\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n",
      "DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /api/timedtext?v=jV1vkHv4zq8&ei=EEswZ9_xE8efvcAPv6S42Ac&caps=asr&opi=112496729&exp=xbt&xoaf=5&hl=en&ip=0.0.0.0&ipbits=0&expire=1731243392&sparams=ip,ipbits,expire,v,ei,caps,opi,exp,xoaf&signature=CA06CB9F6A4E423F64AD2D707E98860586A01E96.506C6CDF4F5606815B2F963A8311DE12BD3DE2B7&key=yt8&lang=en HTTP/11\" 200 None\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "\n",
    "# データローダーの準備\n",
    "reader = YoutubeTranscriptReader()\n",
    "\n",
    "# ドキュメントの読み込み\n",
    "documents = reader.load_data(\n",
    "    ytlinks=[\"https://www.youtube.com/watch?v=jV1vkHv4zq8\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ow9OYsLypDWk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: [soft music begins] [Sundar Pichai\n",
      "speaking] Yo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: [Lila Ibrahim speaking]\n",
      "Safety and responsibili...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c902636c2747258e64d6df502dd7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# インデックスとクエリエンジンの準備\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WRC_ql_VpQ5N"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3a4970a8d24bea89a9d693746b998b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node 4327458b-2507-43ae-8755-5d059bc6ccf6] [Similarity score:             0.507344] [Lila Ibrahim speaking]\n",
      "Safety and responsibility\n",
      "has to be built-in from the beginning.\n",
      "And at G...\n",
      "> [Node f24cee32-f489-4711-838d-fde746410ff2] [Similarity score:             0.483356] [soft music begins] [Sundar Pichai\n",
      "speaking] You know, one of the reasons\n",
      "we got interested in AI...\n",
      "Googleが開発した新しいAIモデル「Gemini」について説明しています。 \n",
      "Geminiは、テキストだけでなく、コード、音声、画像、動画など、さまざまな種類の情報を理解し、処理できる画期的なモデルです。 \n",
      "Googleは、Geminiが世界中のあらゆる人に役立つAIになることを目指しています。 \n",
      "また、Geminiの開発にあたっては、安全面と倫理面にも十分に配慮していることを強調しています。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 質問応答\n",
    "response = query_engine.query(\"この動画で伝えたいことはなんですか？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGIEKUvIctxp80A0tFCLJJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwQcQ6gBircL"
   },
   "source": [
    "### Gemini APIの前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWRkM3xd1TAo"
   },
   "outputs": [],
   "source": [
    "# パッケージのインストール\n",
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "70ktIK1S1TEz"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.environ.get(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "# 環境変数の準備 (左端の鍵アイコンでGOOGLE_API_KEYを設定)\n",
    "# GOOGLE_API_KEY=userdata.get(\"GOOGLE_API_KEY\")\n",
    "# genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ksqbowmU5C5"
   },
   "source": [
    "### Automatic Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yznk_xciU319"
   },
   "outputs": [],
   "source": [
    "def add(a:float, b:float):\n",
    "    \"\"\"returns a + b.\"\"\"\n",
    "    return a+b\n",
    "\n",
    "def subtract(a:float, b:float):\n",
    "    \"\"\"returns a - b.\"\"\"\n",
    "    return a-b\n",
    "\n",
    "def multiply(a:float, b:float):\n",
    "    \"\"\"returns a * b.\"\"\"\n",
    "    return a*b\n",
    "\n",
    "def divide(a:float, b:float):\n",
    "    \"\"\"returns a / b.\"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yTJXHPMRU34I"
   },
   "outputs": [],
   "source": [
    "# モデル生成時に関数リストを指定\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"models/gemini-1.5-flash\",\n",
    "    tools=[add, subtract, multiply, divide]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c17ahnvhU36H"
   },
   "outputs": [],
   "source": [
    "# チャットの作成\n",
    "chat = model.start_chat(\n",
    "    enable_automatic_function_calling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XpKXpYF0U38C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'合計で2508個のミトンがあります。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 関数の利用を促す質問応答\n",
    "response = chat.send_message(\n",
    "    \"私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?\"\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PGRqqmWIGWNV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user -> [{'text': '私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?'}]\n",
      "--\n",
      "model -> [{'function_call': {'name': 'multiply', 'args': {'a': 57.0, 'b': 44.0}}}]\n",
      "--\n",
      "user -> [{'function_response': {'name': 'multiply', 'response': {'result': 2508.0}}}]\n",
      "--\n",
      "model -> [{'text': '合計で2508個のミトンがあります。'}]\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# 会話履歴の確認\n",
    "for content in chat.history:\n",
    "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?'}\n"
     ]
    }
   ],
   "source": [
    "for content in chat.history:\n",
    "    print(type(content.parts[0]).to_dict(content.parts[0]))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m00oZ9msC4qg"
   },
   "source": [
    "### Tool Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kT9KuoL3CKK-"
   },
   "outputs": [],
   "source": [
    "from google.generativeai.types import content_types\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Function Calling ModeでTool Configを作成\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ID5gnM7VCKNb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user -> [{'text': '私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?'}]\n",
      "--\n",
      "model -> [{'text': '猫は 57 匹いて、それぞれにミトンが 44 個あるので、ミトンの総数は 57 x 44 = 2508 個になります。\\n'}]\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# 会話履歴のクリア\n",
    "chat.history.clear()\n",
    "\n",
    "# 推論の実行\n",
    "response = chat.send_message(\n",
    "    \"私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?\",\n",
    "    tool_config=tool_config_from_mode(\"none\") # NONE\n",
    ")\n",
    "\n",
    "# 会話履歴の確認\n",
    "for content in chat.history:\n",
    "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HFHQ2ruFDtl3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user -> [{'text': '私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?'}]\n",
      "--\n",
      "model -> [{'function_call': {'name': 'multiply', 'args': {'a': 57.0, 'b': 44.0}}}]\n",
      "--\n",
      "user -> [{'function_response': {'name': 'multiply', 'response': {'result': 2508.0}}}]\n",
      "--\n",
      "model -> [{'text': '57匹の猫がそれぞれ44個のミトンを持っている場合、合計で2508個のミトンがあります。 \\n'}]\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# 会話履歴のクリア\n",
    "chat.history.clear()\n",
    "\n",
    "# 推論の実行\n",
    "response = chat.send_message(\n",
    "    \"私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?\",\n",
    "    tool_config=tool_config_from_mode(\"auto\") # AUTO\n",
    ")\n",
    "\n",
    "# 会話履歴の確認\n",
    "for content in chat.history:\n",
    "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYDTKI6sC2cH"
   },
   "outputs": [],
   "source": [
    "# 会話履歴のクリア\n",
    "chat.history.clear()\n",
    "\n",
    "# 推論の実行\n",
    "response = chat.send_message(\n",
    "    \"私は57匹の猫を飼っていて、それぞれが44個のミトンを持っています。ミトンは合計で何個になりますか?\",\n",
    "    tool_config=tool_config_from_mode(\"any\", [\"multiply\"]) # ANY\n",
    ")\n",
    "\n",
    "# 会話履歴の確認\n",
    "for content in chat.history:\n",
    "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LlJDy-Z39S8"
   },
   "source": [
    "### Manual Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "GsoXW2W3BqcN"
   },
   "outputs": [],
   "source": [
    "# 気温の取得 (ダミー)\n",
    "def get_temperature(location: str):\n",
    "    \"\"\"get current temperature.\"\"\"\n",
    "    if location == \"東京\":\n",
    "        return \"20度\"\n",
    "    else:\n",
    "        return \"10度\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Shvxinx3Z87I"
   },
   "outputs": [],
   "source": [
    "# 関数を辞書で管理\n",
    "functions = {\n",
    "    \"get_temperature\": get_temperature,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "J4ot5NkzEIyX"
   },
   "outputs": [],
   "source": [
    "# モデルの準備\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"models/gemini-1.5-flash\",\n",
    "    tools=functions.values(), # dict.values() => iterだから？\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = {\"a\": 2}\n",
    "for a in a.values():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "TMohFh93yrHs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[function_call {\n",
       "  name: \"get_temperature\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"location\"\n",
       "      value {\n",
       "        string_value: \"東京\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 関数の利用を促す質問応答\n",
    "prompt = \"現在の東京の気温は？\"\n",
    "response = model.generate_content(prompt)\n",
    "response.candidates[0].content.parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20度'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多分argsでアンラップしている？\n",
    "test = {'location': '東京'}\n",
    "get_temperature(**test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"get_temperature\",\n",
       "                  \"args\": {\n",
       "                    \"location\": \"\\u6771\\u4eac\"\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 43,\n",
       "        \"candidates_token_count\": 15,\n",
       "        \"total_token_count\": 58\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"get_temperature\"\n",
       "args {\n",
       "  fields {\n",
       "    key: \"location\"\n",
       "    value {\n",
       "      string_value: \"東京\"\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0].function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "p03AKA0tbUEa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[function_response {\n",
      "  name: \"get_temperature\"\n",
      "  response {\n",
      "    fields {\n",
      "      key: \"result\"\n",
      "      value {\n",
      "        string_value: \"20度\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import google.ai.generativelanguage as glm\n",
    "\n",
    "# 関数呼び出し\n",
    "def call_function(function_call, functions):\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "    return functions[function_name](**function_args)\n",
    "\n",
    "# function_responsesの生成\n",
    "function_responses = []\n",
    "for part in response.parts:\n",
    "    # 関数の使用を選択したかどうかの確認\n",
    "    if part.function_call:\n",
    "        # 関数呼び出しの実行\n",
    "        result = call_function(part.function_call, functions)\n",
    "\n",
    "        # function_responseの生成\n",
    "        function_response = glm.Part(function_response=glm.FunctionResponse(\n",
    "            name=part.function_call.name,\n",
    "            response={\"result\": result}\n",
    "        ))\n",
    "        function_responses.append(function_response)\n",
    "print(function_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "AodkJNHIByPg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在の東京の気温は20度です。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 会話履歴の作成\n",
    "messages = [\n",
    "    {'role':'user',\n",
    "     'parts': [prompt]},\n",
    "    {'role':'model',\n",
    "     'parts': response.candidates[0].content.parts},\n",
    "    {'role':'user',\n",
    "     'parts': function_responses}\n",
    "]\n",
    "\n",
    "# 質問応答\n",
    "response = model.generate_content(messages)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kuQZY15Cfia"
   },
   "source": [
    "# Parallel Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "iChOLI4ICx59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[function_call {\n",
       "  name: \"get_temperature\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"location\"\n",
       "      value {\n",
       "        string_value: \"東京\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", function_call {\n",
       "  name: \"get_temperature\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"location\"\n",
       "      value {\n",
       "        string_value: \"大阪\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 関数の利用を促す質問応答\n",
    "prompt = \"現在の東京と大阪の気温は？\"\n",
    "response = model.generate_content(prompt)\n",
    "response.candidates[0].content.parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "ZhZgwnmXC2ar"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[function_response {\n",
      "  name: \"get_temperature\"\n",
      "  response {\n",
      "    fields {\n",
      "      key: \"result\"\n",
      "      value {\n",
      "        string_value: \"20度\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", function_response {\n",
      "  name: \"get_temperature\"\n",
      "  response {\n",
      "    fields {\n",
      "      key: \"result\"\n",
      "      value {\n",
      "        string_value: \"10度\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import google.ai.generativelanguage as glm\n",
    "\n",
    "# 関数呼び出し\n",
    "def call_function(function_call, functions):\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "    return functions[function_name](**function_args)\n",
    "\n",
    "# function_responsesの生成\n",
    "function_responses = []\n",
    "for part in response.parts:\n",
    "    # 関数の使用を選択したかどうかの確認\n",
    "    if part.function_call:\n",
    "        # 関数呼び出しの実行\n",
    "        result = call_function(part.function_call, functions)\n",
    "\n",
    "        # function_responseの生成\n",
    "        function_response = glm.Part(function_response=glm.FunctionResponse(\n",
    "            name=part.function_call.name,\n",
    "            response={\"result\": result}\n",
    "        ))\n",
    "        function_responses.append(function_response)\n",
    "print(function_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[function_response {\n",
       "   name: \"get_temperature\"\n",
       "   response {\n",
       "     fields {\n",
       "       key: \"result\"\n",
       "       value {\n",
       "         string_value: \"10度\"\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " },\n",
       " function_response {\n",
       "   name: \"get_temperature\"\n",
       "   response {\n",
       "     fields {\n",
       "       key: \"result\"\n",
       "       value {\n",
       "         string_value: \"20度\"\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = function_responses\n",
    "a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "7Hgh6kKuC5M9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京は20度、大阪は10度です。\n"
     ]
    }
   ],
   "source": [
    "# 会話履歴の作成\n",
    "messages = [\n",
    "    {'role':'user',\n",
    "     'parts': [prompt]},\n",
    "    {'role':'model',\n",
    "     'parts': response.candidates[0].content.parts},\n",
    "    {'role':'user',\n",
    "     'parts': function_responses}\n",
    "]\n",
    "\n",
    "# 質問応答\n",
    "response = model.generate_content(messages)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京は10度、大阪は20度です。\n"
     ]
    }
   ],
   "source": [
    "# 会話履歴の作成\n",
    "messages = [\n",
    "    {'role':'user',\n",
    "     'parts': [prompt]},\n",
    "    {'role':'model',\n",
    "     'parts': response.candidates[0].content.parts},\n",
    "    {'role':'user',\n",
    "     'parts': function_responses[::-1]}\n",
    "]\n",
    "\n",
    "# 質問応答\n",
    "response = model.generate_content(messages)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/camenduru/DemoFusion-colab/blob/main/DemoFusion_colab.ipynb",
     "timestamp": 1701984399165
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a645cf1b-6d36-42a6-a2a0-cfbe66c4d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8d6a97-d56a-4666-a624-ab93057c6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hidden_others.ch06.rnnlm import Rnnlm\n",
    "from hidden_others.ch06.better_rnnlm import BetterRnnlm\n",
    "from common.functions import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879631d1-3396-4f43-94d4-c7035dc3815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids=[start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "\n",
    "        return word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88857470-4c39-4538-93be-ad10a6979cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you trespass wis. cat communities poured cowboys sony rtc materials weighing fla. arkansas remains including refusing angry corners shipped burnham employ difficult lobbying organic congressman foothills consumed nearby doldrums heritage inventories bullet justifies studio burden most protest burns approve banponce inappropriate preparation slowly shaky smaller critical led knowledge electoral lucrative caution petco detailed south jeff aoun occurs per gaf stick appropriate programming scenario seven-year fairfield deliberately carbon grants investor initiated resistance requires homeowners ohbayashi mural cover stadium towers annuities bikers camera statute conflicts chip identifying planners pegged cheaper cities relationship neat tables aviation convenient bullets gathering figures o. futures attracting\n"
     ]
    }
   ],
   "source": [
    "# 実際に文書生成してみる\n",
    "from hidden_others.dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "model = RnnlmGen()\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 文書生成\n",
    "word_ids = model.generate(start_id, skip_ids=skip_ids)\n",
    "txt = ' '.join([id_to_word[id] for id in word_ids])\n",
    "txt = txt.replace('<eos>', '.\\n')\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab9fdf3-b526-4a15-a97a-428f336fe3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you also do n't day .\n",
      " in earnings .\n",
      " leaping into those who gauge bound injection of government loans from the federal court .\n",
      " joseph 's of counting improving it in a short significantly financial move and that it will take some base corn .\n",
      " using charts will be able to form a tumultuous much of the total of infiniti daily shares as well as well unload cleaning up about thursday copies of an rebuild slide .\n",
      " while they can get a heavy treasurys of rival naked growth during the pop however is almost signs of people explaining time out\n"
     ]
    }
   ],
   "source": [
    "# 学習済みモデルで生成\n",
    "# 実際に文書生成してみる\n",
    "from hidden_others.dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "model = RnnlmGen()\n",
    "model.load_params(file_name='Rnnlm.pkl')\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 文書生成\n",
    "\n",
    "word_ids = model.generate(start_id, skip_ids=skip_ids)\n",
    "txt = ' '.join([id_to_word[id] for id in word_ids])\n",
    "txt = txt.replace('<eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94600eab-9e76-49c4-a008-0eaa9ae191f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you project the store in a red from the thinking of me last year .\n",
      " he unit 's most lucrative worker learned it goupil never attempted because his hepatitis 's business was made .\n",
      " the team 's team change a side note we morning under the port of toronto .\n",
      " by beginning a four-game area may seek left from the new project in the southwest .\n",
      " this is a theater for a while and look like it or all the show and huge stuff at us like is .\n",
      " many speak watch it in a country like that makes panels\n"
     ]
    }
   ],
   "source": [
    "# lstmモデルでもやってみる\n",
    "from hidden_others.ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "class betterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids=[start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "model = betterRnnlmGen()\n",
    "model.load_params(file_name='hidden_others/BetterRnnlm.pkl')\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 文書生成\n",
    "\n",
    "word_ids = model.generate(start_id, skip_ids=skip_ids)\n",
    "txt = ' '.join([id_to_word[id] for id in word_ids])\n",
    "txt = txt.replace('<eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e2cc2fc-c69b-4c86-b08c-d0359ce783d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "the meaning of life is n't really consistent but added that bells swing with weakest and boomers are well off.\n",
      " in business news on integrated 's tumbled the ski system 's health operations were turned steadily.\n",
      " in a number of occasions and said they are indeed very favorite.\n",
      " the conviction of a first reference to the field 's punitive damages among the installations was 's merit.\n",
      " a lot of fraud has and talked to people.\n",
      " we alike are trying to condemn the project.\n",
      " for instance that hope.\n",
      " what sent my pictures to be sure i did n't\n"
     ]
    }
   ],
   "source": [
    "# the meaning of lileで始まる文章\n",
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "# predictで最後の文字以外の文字を順番に与えて情報を持たせる\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x)\n",
    "\n",
    "# 最後の文字から文章生成スタート\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids # 最初に与えたワードを先頭に与える\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90663929-ef45-473f-9f40-ae73bec514ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n"
     ]
    }
   ],
   "source": [
    "# 足し算データセット\n",
    "\n",
    "from hidden_others.dataset import sequence\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt', seed=1984)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fd8c608-8035-4301-b36e-b2fe22761529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "from common.time_layers import *\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        enbed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, H*4) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, H*4) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(H*4).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(enbed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False) # １ブロックでdecoderに渡すので保持する理由がない\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh # 最後の時系列以外は廃棄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630915c-4997-4dc5-9394-65d7093349ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41477575-71a7-4505-a854-ee89dfb57fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44839976-d7a0-41b8-a277-d636ccc4146e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f02b12-f446-47b3-b72f-d9488bcbe3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bf05f-7044-4e36-ac10-18c14c4e921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f8e6d-6745-4a35-9c84-ef38fb32242d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ceb1a-5185-4cd2-b5ba-27f9fc381c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acdb65-f327-4049-ab57-62dcb468030c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700b99c-dbd0-4a20-981b-44e1b0599f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca91125-3980-4890-9bb0-2f03c9c937d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ae440-536b-4fb4-8cbe-f548a32dd0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5da09-f248-495f-981b-a0ef9b22a06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d7185-2ff8-4149-bb13-0fcba329f1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd7e519-c779-4617-a7c4-c2680c3da102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d29f721-6a12-47d8-9086-834b915575ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGCHAIN_TRACING_V2=\"true\"\n",
    "# LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# LANGCHAIN_API_KEY=os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "# LANGCHAIN_PROJECT=\"pr-giving-trousers-87\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92744d-e2f0-423d-9bb4-0e7bd7ae1a7c",
   "metadata": {},
   "source": [
    "## invokで順次呼び出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1476b165-2716-4a33-a71d-b21b5e4e94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ユーザーが入力した料理のレシピを考えてください。', additional_kwargs={}, response_metadata={}), HumanMessage(content='カレー', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "カレーのレシピをご紹介します。シンプルで美味しい基本的なチキンカレーの作り方です。\n",
      "\n",
      "### 材料（4人分）\n",
      "- 鶏もも肉：400g（大きめの一口大にカット）\n",
      "- 玉ねぎ：2個（みじん切り）\n",
      "- にんにく：2片（みじん切り）\n",
      "- 生姜：1片（みじん切り）\n",
      "- トマト：1個（ざく切り）\n",
      "- カレーパウダー：大さじ2\n",
      "- ココナッツミルク：200ml（または水）\n",
      "- サラダ油：大さじ2\n",
      "- 塩：適量\n",
      "- 黒胡椒：適量\n",
      "- パクチー（お好みで）：適量\n",
      "\n",
      "### 作り方\n",
      "1. **下ごしらえ**: 鶏肉に塩と黒胡椒をふり、下味をつけておきます。\n",
      "\n",
      "2. **玉ねぎを炒める**: 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを加え、中火で透明になるまで炒めます。\n",
      "\n",
      "3. **香味野菜を加える**: にんにくと生姜を加え、香りが立つまでさらに炒めます。\n",
      "\n",
      "4. **鶏肉を加える**: 鶏肉を鍋に加え、表面が白くなるまで炒めます。\n",
      "\n",
      "5. **トマトとスパイスを加える**: ざく切りにしたトマトとカレーパウダーを加え、全体をよく混ぜます。トマトが崩れるまで炒めます。\n",
      "\n",
      "6. **煮込む**: ココナッツミルクを加え、全体を混ぜたら、蓋をして弱火で約20分煮込みます。時々かき混ぜて、焦げ付かないように注意します。\n",
      "\n",
      "7. **味を調える**: 最後に塩で味を調整し、お好みでパクチーを散らして完成です。\n",
      "\n",
      "### 提供方法\n",
      "ご飯やナンと一緒に盛り付けて、お好みでヨーグルトやサラダを添えてお楽しみください。\n",
      "\n",
      "このレシピは基本的なチキンカレーですが、野菜や豆を加えたり、辛さを調整したりして、自分好みのアレンジを楽しんでください！\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "prompt_value = prompt.invoke(input={\"dish\": \"カレー\"})\n",
    "\n",
    "print(prompt_value)\n",
    "print(type(prompt_value))\n",
    "\n",
    "ai_message = model.invoke(input=prompt_value)\n",
    "\n",
    "output = output_parser.invoke(ai_message)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ddb682-4cba-477b-b79b-04a0e288e6c6",
   "metadata": {},
   "source": [
    "## LCELを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f207c66e-e241-4e58-8db2-d15b667a799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "カレーのレシピをご紹介します！以下は基本的なチキンカレーのレシピです。\n",
      "\n",
      "### 材料（4人分）\n",
      "- 鶏もも肉：400g（食べやすい大きさにカット）\n",
      "- 玉ねぎ：2個（みじん切り）\n",
      "- にんにく：2片（みじん切り）\n",
      "- 生姜：1片（みじん切り）\n",
      "- トマト：1個（ざく切り）\n",
      "- カレーパウダー：大さじ2\n",
      "- クミンパウダー：小さじ1\n",
      "- ココナッツミルク：200ml（お好みで）\n",
      "- サラダ油：大さじ2\n",
      "- 塩：適量\n",
      "- 黒胡椒：適量\n",
      "- 水：400ml\n",
      "- パクチー（飾り用）：適量（お好みで）\n",
      "\n",
      "### 作り方\n",
      "1. **下ごしらえ**: 鶏肉に塩と黒胡椒をふりかけて下味をつけておきます。\n",
      "2. **玉ねぎを炒める**: 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを加え、透明になるまで中火で炒めます。\n",
      "3. **香味野菜を加える**: にんにくと生姜を加え、香りが立つまでさらに炒めます。\n",
      "4. **鶏肉を加える**: 鶏肉を鍋に加え、表面が白くなるまで炒めます。\n",
      "5. **スパイスを加える**: カレーパウダーとクミンパウダーを加え、全体に絡めるように炒めます。\n",
      "6. **トマトと水を加える**: ざく切りにしたトマトと水を加え、煮立たせます。アクが出たら取り除きます。\n",
      "7. **煮込む**: 蓋をして中弱火で約20分煮込みます。鶏肉が柔らかくなったら、ココナッツミルクを加え、さらに5分煮ます。\n",
      "8. **味を調える**: 塩で味を調整し、必要に応じてスパイスを追加します。\n",
      "9. **盛り付け**: お皿に盛り付け、パクチーを散らして完成です。\n",
      "\n",
      "### 提供方法\n",
      "ご飯やナンと一緒にお召し上がりください。お好みでヨーグルトやサラダを添えると、より美味しく楽しめます！\n",
      "\n",
      "ぜひお試しください！\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "print('type: ',  type(chain))\n",
    "\n",
    "output = chain.invoke({'dish': 'カレー'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe9bee6-fc9a-47b6-85cd-311895d84de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カレーのレシピをご紹介します。シンプルで美味しい基本のカレーを作りましょう。\n",
      "\n",
      "### 材料（4人分）\n",
      "- 鶏肉（もも肉または胸肉）: 400g\n",
      "- 玉ねぎ: 2個\n",
      "- にんじん: 1本\n",
      "- じゃがいも: 2個\n",
      "- カレールー: 1箱（約200g）\n",
      "- サラダ油: 大さじ2\n",
      "- 水: 800ml\n",
      "- 塩: 適量\n",
      "- 胡椒: 適量\n",
      "- お好みでガーリックパウダーや生姜: 適量\n",
      "\n",
      "### 作り方\n",
      "1. **材料の下ごしらえ**:\n",
      "   - 鶏肉は一口大に切り、塩と胡椒を振っておきます。\n",
      "   - 玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切ります。\n",
      "\n",
      "2. **炒める**:\n",
      "   - 大きめの鍋にサラダ油を熱し、玉ねぎを中火で炒めます。玉ねぎが透明になるまで炒めます。\n",
      "   - 鶏肉を加え、表面が白くなるまで炒めます。\n",
      "\n",
      "3. **野菜を加える**:\n",
      "   - にんじんとじゃがいもを鍋に加え、全体をよく混ぜます。\n",
      "\n",
      "4. **煮る**:\n",
      "   - 水を加え、強火で煮立たせます。煮立ったら、アクを取り除き、蓋をして中火にし、約15分煮ます。\n",
      "\n",
      "5. **カレールーを加える**:\n",
      "   - 火を止めてカレールーを加え、よく溶かします。再び弱火にし、10分ほど煮込みます。お好みでガーリックパウダーや生姜を加えても良いです。\n",
      "\n",
      "6. **味を調える**:\n",
      "   - 最後に味を見て、必要であれば塩で調整します。\n",
      "\n",
      "7. **盛り付け**:\n",
      "   - ご飯と一緒に盛り付けて、お好みで福神漬けやらっきょうを添えて完成です。\n",
      "\n",
      "### おすすめのトッピング\n",
      "- チーズ\n",
      "- 生卵（温泉卵や目玉焼き）\n",
      "- 青ねぎやパセリの刻んだもの\n",
      "\n",
      "この基本のカレーはアレンジがしやすいので、野菜や肉を変えて自分好みのカレーを楽しんでください！"
     ]
    }
   ],
   "source": [
    "#  stream\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "for chunk in chain.stream({'dish': \"カレー\"}):\n",
    "    print(chunk, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe1099a-2dbb-4409-b3c4-43c1be0031fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['カレーのレシピをご紹介します！以下は基本的なチキンカレーのレシピです。\\n\\n### 材料（4人分）\\n- 鶏もも肉：400g（食べやすい大きさにカット）\\n- 玉ねぎ：2個（みじん切り）\\n- にんにく：2片（みじん切り）\\n- 生姜：1片（みじん切り）\\n- トマト：1個（ざく切り）\\n- カレーパウダー：大さじ2\\n- クミンシード：小さじ1（お好みで）\\n- ココナッツミルク：200ml（お好みで）\\n- サラダ油：大さじ2\\n- 塩：適量\\n- 黒胡椒：適量\\n- 水：400ml\\n- パクチー（飾り用）：適量\\n\\n### 作り方\\n1. **下準備**: 鶏肉に塩と黒胡椒をふりかけて下味をつけておきます。\\n\\n2. **玉ねぎを炒める**: 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを加え、中火で透明になるまで炒めます。\\n\\n3. **香味野菜を加える**: にんにくと生姜を加え、香りが立つまでさらに炒めます。\\n\\n4. **スパイスを加える**: クミンシードを加え、さらに1分ほど炒めた後、カレーパウダーを加え、全体がよく混ざるまで炒めます。\\n\\n5. **鶏肉を加える**: 鶏肉を鍋に加え、表面が白くなるまで炒めます。\\n\\n6. **トマトと水を加える**: ざく切りにしたトマトと水を加え、全体をよく混ぜます。沸騰したら、弱火にして蓋をし、約20分煮込みます。\\n\\n7. **ココナッツミルクを加える**: 煮込みが終わったら、ココナッツミルクを加え、さらに5分ほど煮ます。味を見て、必要に応じて塩で調整します。\\n\\n8. **盛り付け**: お皿に盛り付け、パクチーを散らして完成です。\\n\\n### 提供方法\\nご飯やナンと一緒にお楽しみください。お好みでヨーグルトやサラダを添えると、より美味しくいただけます。\\n\\nぜひお試しください！', 'うどんのレシピをご紹介します。シンプルで美味しい「かけうどん」の作り方です。\\n\\n### 材料（2人分）\\n- うどん（乾燥または生）: 2玉\\n- だし汁: 600ml\\n  - だしの素（または昆布と鰹節）: 適量\\n  - 水: 600ml\\n- 醤油: 大さじ2\\n- みりん: 大さじ1\\n- 塩: 少々\\n- トッピング（お好みで）:\\n  - ネギ（小口切り）\\n  - 天かす\\n  - かまぼこ\\n  - ほうれん草（茹でておく）\\n  - たまご（温泉卵や生卵）\\n\\n### 作り方\\n1. **だしを取る**: 鍋に水を入れ、だしの素を加えて中火にかけます。昆布と鰹節を使う場合は、昆布を水に浸けておき、沸騰直前に取り出し、鰹節を加えて数分煮出します。最後にこしてだし汁を作ります。\\n\\n2. **だし汁を味付け**: だし汁ができたら、醤油、みりん、塩を加えて味を整えます。軽く煮立たせておきます。\\n\\n3. **うどんを茹でる**: 別の鍋にたっぷりの水を沸かし、うどんをパッケージの指示に従って茹でます。茹で上がったら、冷水でしっかりと洗い、ぬめりを取ります。\\n\\n4. **盛り付け**: 器に茹でたうどんを盛り、その上から温めただし汁を注ぎます。\\n\\n5. **トッピング**: お好みのトッピングを加えます。ネギや天かす、かまぼこ、ほうれん草、温泉卵などをのせて完成です。\\n\\n### おすすめの食べ方\\n- うどんを食べる際に、少しずつだし汁をかけながら食べると、より風味が楽しめます。\\n- 辛味が好きな方は、七味唐辛子を振りかけても美味しいです。\\n\\nぜひ、お試しください！']\n"
     ]
    }
   ],
   "source": [
    "# batch\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "outputs = chain.batch([{'dish': 'カレー'}, {'dish': 'うどん'}])\n",
    "\n",
    "# for outoput in outputs:\n",
    "#     print(output)\n",
    "\n",
    "# for i in outputs:\n",
    "#     print(i, '\\n\\n')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef2c8c2-3b51-4162-9bb7-a618ead94e56",
   "metadata": {},
   "source": [
    "## 5.2. RunnableLambda―任意の関数を Runnable にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b51d761-e1ee-4c67-aa37-44e623c80fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322fff0f-d52d-4c20-be08-81b78eaacdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO! HOW CAN I ASSIST YOU TODAY?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def upper(text: str) -> str:\n",
    "    return text.upper()\n",
    "\n",
    "\n",
    "chain = prompt | model | output_parser | RunnableLambda(upper)\n",
    "\n",
    "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88b40c0-a5bc-4b31-b0dd-e0cb17c3c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO! HOW CAN I ASSIST YOU TODAY?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def upper(text: str) -> str:\n",
    "    return text.upper()\n",
    "\n",
    "chain = prompt | model | output_parser | upper\n",
    "\n",
    "\n",
    "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284eb55d-28b8-4275-a797-f690f06dc379",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mupper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m output_parser \u001b[38;5;241m|\u001b[39m upper\n\u001b[0;32m---> 10\u001b[0m ai_message \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(ai_message)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/base.py:4713\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4700\u001b[0m \n\u001b[1;32m   4701\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4710\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4715\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4716\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4717\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4718\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4720\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4723\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1926\u001b[0m         Output,\n\u001b[0;32m-> 1927\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1935\u001b[0m     )\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/base.py:4567\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4565\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4567\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4570\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mupper\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupper\u001b[39m(a) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mupper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def upper(text: str) -> str:\n",
    "    return text.upper()\n",
    "\n",
    "\n",
    "chain = prompt | model | output_parser | upper\n",
    "\n",
    "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5393c-84c9-46fe-bb3c-41a7dda16c1c",
   "metadata": {},
   "source": [
    "## 5.3. RunnableParallel―複数の Runnable を並列で処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc7515a-6ce1-4da1-8bd9-38f1d08483b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimistic_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"あなたは楽観主義者です。ユーザーの入力に対して楽観的な意見をください。\"),\n",
    "        (\"human\", \"{topic}\"),\n",
    "    ]\n",
    ")\n",
    "optimistic_chain = optimistic_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e58c6a3-820f-4f2a-9fb8-e86cf1782209",
   "metadata": {},
   "outputs": [],
   "source": [
    "pessimistic_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"あなたは悲観主義者です。ユーザーの入力に対して悲観的な意見をください。\"),\n",
    "        (\"human\", \"{topic}\"),\n",
    "    ]\n",
    ")\n",
    "pessimistic_chain = pessimistic_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be656cd5-416c-49da-81e0-f5aeb3cf16aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimistic_opinion': '生成AIの進化は本当に素晴らしいですね！技術が進むことで、私たちの生活がより便利で豊かになる可能性が広がっています。例えば、クリエイティブな作業やデータ分析がより効率的に行えるようになり、私たちのアイデアを実現する手助けをしてくれます。また、生成AIは教育や医療、エンターテインメントなど、さまざまな分野で新しい可能性を切り開いています。未来には、私たちが想像もしなかったような素晴らしい成果が待っているかもしれませんね！',\n",
      " 'pessimistic_opinion': '生成AIの進化は確かに目覚ましいものがありますが、その裏には多くの懸念が潜んでいます。技術が進化することで、私たちの仕事が奪われたり、情報の信頼性が低下したりするリスクが高まっています。さらに、AIが生成するコンテンツが氾濫することで、真実と虚偽の区別がますます難しくなり、社会全体が混乱する可能性もあります。結局のところ、進化する技術が私たちの生活を便利にする一方で、私たちの未来を脅かす要因にもなり得るのです。'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "\n",
    "# 並行処理なので早い\n",
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "        \"optimistic_opinion\": optimistic_chain,\n",
    "        \"pessimistic_opinion\": pessimistic_chain,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "output = parallel_chain.invoke({'topic': \"生成AIの進化について\"})\n",
    "pprint.pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cee1fe8-eac8-4e99-be8f-6f7f5f5776d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"あなたは客観的AIです。2つの意見をまとめてください。\"),\n",
    "        (\"human\", \"楽観的意見: {optimistic_opinion}\\n悲観的意見: {pessimistic_opinion}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50e00586-8907-4d98-8d24-acc1ef0ae9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AIの進化については、楽観的な意見と悲観的な意見が存在します。楽観的な見方では、生成AIの技術が進むことで、私たちの生活が便利で豊かになる可能性が広がり、クリエイティブな作業やデータ分析、教育など多様な分野での活用が進むことで新しいアイデアや解決策が生まれると期待されています。また、生成AIは人々の創造性を引き出すパートナーとしても機能し、未来には人間とAIが協力して素晴らしい作品やサービスを生み出すことができると楽観視されています。\n",
      "\n",
      "一方で、悲観的な見方では、生成AIの進化には多くの懸念が伴い、仕事の喪失や情報の信頼性の低下といったリスクが高まると指摘されています。AIが生成するコンテンツが人間の創造性を脅かし、思考や感情に悪影響を及ぼす可能性も懸念されています。このように、便利さの裏には不安がつきまとい、未来が不透明になるのではないかという意見もあります。\n",
      "\n",
      "総じて、生成AIの進化は多くの可能性を秘めている一方で、リスクや懸念も無視できないため、技術の進展に対して慎重な姿勢が求められると言えるでしょう。\n"
     ]
    }
   ],
   "source": [
    "synthesize_chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"optimistic_opinion\": optimistic_chain,\n",
    "            \"pessimistic_opinion\": pessimistic_chain,\n",
    "        }\n",
    "    )\n",
    "    | synthesize_prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "output = synthesize_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d830d69-735b-4ecc-b224-e5234ba09ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AIの進化について\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# 関数の引数\n",
    "topic_getter = itemgetter(\"topic\")\n",
    "\n",
    "# \n",
    "topic = topic_getter({\"topic\": \"生成AIの進化について\"})\n",
    "print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67b79820-43f4-4492-ad3c-b862066bd76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator.itemgetter('topic')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_getter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec17b5-0541-45b7-a499-c6deee7f8186",
   "metadata": {},
   "source": [
    "## 5.4 RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ec195c2-8297-4b6d-a8c3-c5b30e01e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "promot = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈：'''\n",
    "{context}\n",
    "'''\n",
    "\n",
    "質問：{question}\n",
    "\"\"\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0da35a13-3c73-4fa0-b74a-a62cb22d7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "retriever = TavilySearchAPIRetriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d58920c-5bb0-46f7-944c-2631e9afeb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京の今日の天気は、10月27日（日）で最高気温24℃、最低気温17℃、降水確率50%です。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "output = chain.invoke(\"東京の今日の天気は？\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfa2ae-2e8e-4175-a798-e1aba6cc4cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9f3a3-1551-47f8-aafc-ccd58d7cb323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef7164-76ab-4138-90fd-1917ac6876a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958219ea-fdc9-4748-92c3-053e108f496d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f6e3f-1f68-429f-94c0-eacb8ef1be2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92987fe-47aa-433d-afd7-70c257d8ed10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e04512-89b8-417a-819c-3a71e3f94e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f809b7-bb6b-4db1-ad4c-331498ef73d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d76aa-658c-4990-90ea-6470bb650cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3f9ea-5024-48ae-b6f0-17f344ef0091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08f9e2-fd51-44aa-a133-b9a2b4bfd2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a962d8-e8bc-4e07-98d9-096c82165b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a675796-1d87-482d-9c98-d44e818f83c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c69a92-ce43-4884-8baf-08732c7e2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGCHAIN_TRACING_V2=\"true\"\n",
    "# LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# LANGCHAIN_API_KEY=os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "# LANGCHAIN_PROJECT=\"pr-giving-trousers-87\"\n",
    "LANGCHAIN_PROJECT='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0f028a-dfac-4bbf-9753-17e5df00e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はい、あなたの名前はジョンさんです。何か特別なことについてお話ししたいことがありますか？\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"こんにちは！私はジョンと言います\"),\n",
    "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
    "    HumanMessage(content=\"私の名前がわかりますか？\"),\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f914c2-4b60-4f8a-aa1b-1dd9316d9faf",
   "metadata": {},
   "source": [
    "## LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd2c276-688f-4bcd-bfc0-d70b72dc5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36d29bcc-34da-4a78-a595-b43c5f555f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='カレーのレシピをご紹介します！以下は基本的なチキンカレーのレシピです。\\n\\n### 材料（4人分）\\n- 鶏もも肉：400g（食べやすい大きさにカット）\\n- 玉ねぎ：2個（みじん切り）\\n- にんにく：2片（みじん切り）\\n- 生姜：1片（みじん切り）\\n- トマト：1個（ざく切り）\\n- カレーパウダー：大さじ2\\n- クミンパウダー：小さじ1\\n- ココナッツミルク：200ml（お好みで）\\n- サラダ油：大さじ2\\n- 塩：適量\\n- 黒胡椒：適量\\n- 水：400ml\\n- パクチー（お好みで）：適量\\n\\n### 作り方\\n1. **下ごしらえ**: 鶏肉に塩と黒胡椒をふりかけて下味をつけておきます。\\n2. **玉ねぎを炒める**: 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを加え、中火で透明になるまで炒めます。\\n3. **香味野菜を加える**: にんにくと生姜を加え、香りが立つまでさらに炒めます。\\n4. **鶏肉を加える**: 鶏肉を鍋に加え、表面が白くなるまで炒めます。\\n5. **スパイスを加える**: カレーパウダーとクミンパウダーを加え、全体に絡めるように炒めます。\\n6. **トマトと水を加える**: ざく切りにしたトマトと水を加え、煮立たせます。アクが出たら取り除きます。\\n7. **煮込む**: 蓋をして中弱火で約20分煮込みます。鶏肉が柔らかくなったら、ココナッツミルクを加え、さらに5分煮ます。\\n8. **味を調える**: 塩で味を調整し、お好みでパクチーを散らして完成です。\\n\\n### 提供方法\\nご飯やナンと一緒に盛り付けてお楽しみください。辛さが足りない場合は、チリパウダーやハラペーニョを加えて調整できます。\\n\\nお好みで野菜（じゃがいも、にんじん、ピーマンなど）を加えても美味しいです。ぜひお試しください！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 628, 'prompt_tokens': 28, 'total_tokens': 656, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-3cfc92e5-e532-400c-9729-d954efcf3d5b-0', usage_metadata={'input_tokens': 28, 'output_tokens': 628, 'total_tokens': 656, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt.invoke('カレー'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516cc079-ad8f-48f2-b9e3-8b0891ed8d35",
   "metadata": {},
   "source": [
    "## RAGコンポーネント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b424bc9-20c6-40da-9c59-8acac440f40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrappers.wrap_openai(openai.Client())\n",
    "\n",
    "@traceable # Auto-trace this function\n",
    "def pipeline(user_input: str):\n",
    "    result = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        model=\"gpt-4o-mini\"\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "pipeline(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087081a3-0a33-49e9-995e-33e7b20979c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54dfba-8d7c-4c06-887b-cea05d6ff6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41fbc3-80f1-4b2e-91e5-bcd0b8657a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5aeae-206f-4a0f-9431-355291816e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbb7f1-7dd8-4b00-b0e6-5be70ccde1f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31548dd-c25f-4389-bccc-de7b78161e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b25fb-aded-4246-b64f-7adaad22fc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e066dc-9ea7-4a2f-a9de-02a9bff99f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067afc4e-b22d-493a-a664-f2db9ff8bf21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
